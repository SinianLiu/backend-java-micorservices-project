* 
* ==> Audit <==
* |--------------|-----------|----------|-----------|---------|---------------------|---------------------|
|   Command    |   Args    | Profile  |   User    | Version |     Start Time      |      End Time       |
|--------------|-----------|----------|-----------|---------|---------------------|---------------------|
| start        |           | minikube | sinianliu | v1.31.2 | 15 Oct 23 02:00 PDT | 15 Oct 23 02:13 PDT |
| update-check |           | minikube | sinianliu | v1.31.2 | 18 Oct 23 23:37 PDT | 18 Oct 23 23:37 PDT |
| update-check |           | minikube | sinianliu | v1.31.2 | 19 Oct 23 17:09 PDT | 19 Oct 23 17:09 PDT |
| update-check |           | minikube | sinianliu | v1.31.2 | 21 Oct 23 18:27 PDT | 21 Oct 23 18:27 PDT |
| start        |           | minikube | sinianliu | v1.31.2 | 22 Oct 23 01:22 PDT | 22 Oct 23 01:23 PDT |
| dashboard    |           | minikube | sinianliu | v1.31.2 | 22 Oct 23 10:10 PDT |                     |
| service      | eureka-lb | minikube | sinianliu | v1.31.2 | 22 Oct 23 11:08 PDT |                     |
|--------------|-----------|----------|-----------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/10/22 01:22:56
Running on machine: Sinians-MacBook-Air
Binary: Built with gc go1.21.0 for darwin/arm64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1022 01:22:56.127061   64396 out.go:296] Setting OutFile to fd 1 ...
I1022 01:22:56.127697   64396 out.go:348] isatty.IsTerminal(1) = true
I1022 01:22:56.127700   64396 out.go:309] Setting ErrFile to fd 2...
I1022 01:22:56.127704   64396 out.go:348] isatty.IsTerminal(2) = true
I1022 01:22:56.128266   64396 root.go:338] Updating PATH: /Users/sinianliu/.minikube/bin
W1022 01:22:56.129727   64396 root.go:314] Error reading config file at /Users/sinianliu/.minikube/config/config.json: open /Users/sinianliu/.minikube/config/config.json: no such file or directory
I1022 01:22:56.131215   64396 out.go:303] Setting JSON to false
I1022 01:22:56.162891   64396 start.go:128] hostinfo: {"hostname":"Sinians-MacBook-Air.local","uptime":472445,"bootTime":1697490531,"procs":383,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"13.4","kernelVersion":"22.5.0","kernelArch":"arm64","virtualizationSystem":"","virtualizationRole":"","hostId":"bba91a30-c5e7-5842-9ad3-c5b85fce4f2a"}
W1022 01:22:56.162993   64396 start.go:136] gopshost.Virtualization returned error: not implemented yet
I1022 01:22:56.170138   64396 out.go:177] 😄  minikube v1.31.2 on Darwin 13.4 (arm64)
I1022 01:22:56.178902   64396 notify.go:220] Checking for updates...
I1022 01:22:56.179697   64396 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I1022 01:22:56.180649   64396 driver.go:373] Setting default libvirt URI to qemu:///system
I1022 01:22:56.358256   64396 docker.go:121] docker version: linux-20.10.22:Docker Desktop 4.16.2 (95914)
I1022 01:22:56.358570   64396 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I1022 01:22:56.909284   64396 info.go:266] docker info: {ID:JSXY:4VQH:H3KE:B33A:UXOM:6EYE:FSTS:SOUF:4SR4:7Y65:AMXV:VRPH Containers:4 ContainersRunning:3 ContainersPaused:0 ContainersStopped:1 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:67 OomKillDisable:false NGoroutines:62 SystemTime:2023-10-22 08:22:56.420108055 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:6 KernelVersion:5.15.49-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:8233017344 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.22 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9ba4b250366a5ddde94bb7c9d1def331423aa323 Expected:9ba4b250366a5ddde94bb7c9d1def331423aa323} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/sinianliu/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.10.0] map[Name:compose Path:/Users/sinianliu/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.15.1] map[Name:dev Path:/Users/sinianliu/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-dev] ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.0.5] map[Name:extension Path:/Users/sinianliu/.docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-extension] ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.17] map[Name:sbom Path:/Users/sinianliu/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-sbom] ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/Users/sinianliu/.docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-scan] ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.23.0]] Warnings:<nil>}}
I1022 01:22:56.918083   64396 out.go:177] ✨  Using the docker driver based on existing profile
I1022 01:22:56.922047   64396 start.go:298] selected driver: docker
I1022 01:22:56.922067   64396 start.go:902] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I1022 01:22:56.922115   64396 start.go:913] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I1022 01:22:56.922434   64396 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I1022 01:22:57.101252   64396 info.go:266] docker info: {ID:JSXY:4VQH:H3KE:B33A:UXOM:6EYE:FSTS:SOUF:4SR4:7Y65:AMXV:VRPH Containers:4 ContainersRunning:3 ContainersPaused:0 ContainersStopped:1 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:67 OomKillDisable:false NGoroutines:62 SystemTime:2023-10-22 08:22:56.982545597 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:6 KernelVersion:5.15.49-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:8233017344 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.22 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9ba4b250366a5ddde94bb7c9d1def331423aa323 Expected:9ba4b250366a5ddde94bb7c9d1def331423aa323} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/sinianliu/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.10.0] map[Name:compose Path:/Users/sinianliu/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.15.1] map[Name:dev Path:/Users/sinianliu/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-dev] ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.0.5] map[Name:extension Path:/Users/sinianliu/.docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-extension] ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.17] map[Name:sbom Path:/Users/sinianliu/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-sbom] ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/Users/sinianliu/.docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShadowedPaths:[/usr/local/lib/docker/cli-plugins/docker-scan] ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.23.0]] Warnings:<nil>}}
I1022 01:22:57.101982   64396 cni.go:84] Creating CNI manager for ""
I1022 01:22:57.102125   64396 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1022 01:22:57.102130   64396 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I1022 01:22:57.111039   64396 out.go:177] 👍  Starting control plane node minikube in cluster minikube
I1022 01:22:57.115260   64396 cache.go:122] Beginning downloading kic base image for docker with docker
I1022 01:22:57.119040   64396 out.go:177] 🚜  Pulling base image ...
I1022 01:22:57.127123   64396 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 in local docker daemon
I1022 01:22:57.127315   64396 preload.go:132] Checking if preload exists for k8s version v1.27.4 and runtime docker
I1022 01:22:57.127567   64396 preload.go:148] Found local preload: /Users/sinianliu/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4
I1022 01:22:57.127656   64396 cache.go:57] Caching tarball of preloaded images
I1022 01:22:57.128375   64396 preload.go:174] Found /Users/sinianliu/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4 in cache, skipping download
I1022 01:22:57.128412   64396 cache.go:60] Finished verifying existence of preloaded tar for  v1.27.4 on docker
I1022 01:22:57.128602   64396 profile.go:148] Saving config to /Users/sinianliu/.minikube/profiles/minikube/config.json ...
I1022 01:22:57.194798   64396 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 in local docker daemon, skipping pull
I1022 01:22:57.194808   64396 cache.go:145] gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 exists in daemon, skipping load
I1022 01:22:57.194854   64396 cache.go:195] Successfully downloaded all kic artifacts
I1022 01:22:57.195169   64396 start.go:365] acquiring machines lock for minikube: {Name:mkdc300beb8351f0e3e84a5c1afc50c46868da7c Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1022 01:22:57.195359   64396 start.go:369] acquired machines lock for "minikube" in 164.292µs
I1022 01:22:57.195560   64396 start.go:96] Skipping create...Using existing machine configuration
I1022 01:22:57.195567   64396 fix.go:54] fixHost starting: 
I1022 01:22:57.195810   64396 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1022 01:22:57.264939   64396 fix.go:102] recreateIfNeeded on minikube: state=Running err=<nil>
W1022 01:22:57.264972   64396 fix.go:128] unexpected machine state, will restart: <nil>
I1022 01:22:57.269704   64396 out.go:177] 🏃  Updating the running docker "minikube" container ...
I1022 01:22:57.270899   64396 machine.go:88] provisioning docker machine ...
I1022 01:22:57.271280   64396 ubuntu.go:169] provisioning hostname "minikube"
I1022 01:22:57.271529   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:57.345464   64396 main.go:141] libmachine: Using SSH client type: native
I1022 01:22:57.346411   64396 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10246b730] 0x10246dea0 <nil>  [] 0s} 127.0.0.1 53128 <nil> <nil>}
I1022 01:22:57.346418   64396 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I1022 01:22:57.521225   64396 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I1022 01:22:57.521468   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:57.586846   64396 main.go:141] libmachine: Using SSH client type: native
I1022 01:22:57.587242   64396 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10246b730] 0x10246dea0 <nil>  [] 0s} 127.0.0.1 53128 <nil> <nil>}
I1022 01:22:57.587252   64396 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I1022 01:22:57.714250   64396 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I1022 01:22:57.714280   64396 ubuntu.go:175] set auth options {CertDir:/Users/sinianliu/.minikube CaCertPath:/Users/sinianliu/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/sinianliu/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/sinianliu/.minikube/machines/server.pem ServerKeyPath:/Users/sinianliu/.minikube/machines/server-key.pem ClientKeyPath:/Users/sinianliu/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/sinianliu/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/sinianliu/.minikube}
I1022 01:22:57.714315   64396 ubuntu.go:177] setting up certificates
I1022 01:22:57.715294   64396 provision.go:83] configureAuth start
I1022 01:22:57.715446   64396 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1022 01:22:57.781354   64396 provision.go:138] copyHostCerts
I1022 01:22:57.782002   64396 exec_runner.go:144] found /Users/sinianliu/.minikube/cert.pem, removing ...
I1022 01:22:57.782013   64396 exec_runner.go:203] rm: /Users/sinianliu/.minikube/cert.pem
I1022 01:22:57.782302   64396 exec_runner.go:151] cp: /Users/sinianliu/.minikube/certs/cert.pem --> /Users/sinianliu/.minikube/cert.pem (1131 bytes)
I1022 01:22:57.782674   64396 exec_runner.go:144] found /Users/sinianliu/.minikube/key.pem, removing ...
I1022 01:22:57.782677   64396 exec_runner.go:203] rm: /Users/sinianliu/.minikube/key.pem
I1022 01:22:57.782732   64396 exec_runner.go:151] cp: /Users/sinianliu/.minikube/certs/key.pem --> /Users/sinianliu/.minikube/key.pem (1679 bytes)
I1022 01:22:57.783024   64396 exec_runner.go:144] found /Users/sinianliu/.minikube/ca.pem, removing ...
I1022 01:22:57.783027   64396 exec_runner.go:203] rm: /Users/sinianliu/.minikube/ca.pem
I1022 01:22:57.783077   64396 exec_runner.go:151] cp: /Users/sinianliu/.minikube/certs/ca.pem --> /Users/sinianliu/.minikube/ca.pem (1086 bytes)
I1022 01:22:57.783207   64396 provision.go:112] generating server cert: /Users/sinianliu/.minikube/machines/server.pem ca-key=/Users/sinianliu/.minikube/certs/ca.pem private-key=/Users/sinianliu/.minikube/certs/ca-key.pem org=sinianliu.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I1022 01:22:57.953764   64396 provision.go:172] copyRemoteCerts
I1022 01:22:57.956753   64396 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I1022 01:22:57.956801   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:58.030819   64396 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53128 SSHKeyPath:/Users/sinianliu/.minikube/machines/minikube/id_rsa Username:docker}
I1022 01:22:58.144736   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1086 bytes)
I1022 01:22:58.181140   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/machines/server.pem --> /etc/docker/server.pem (1208 bytes)
I1022 01:22:58.209422   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I1022 01:22:58.237685   64396 provision.go:86] duration metric: configureAuth took 522.354583ms
I1022 01:22:58.237709   64396 ubuntu.go:193] setting minikube options for container-runtime
I1022 01:22:58.238050   64396 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I1022 01:22:58.238178   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:58.314718   64396 main.go:141] libmachine: Using SSH client type: native
I1022 01:22:58.315125   64396 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10246b730] 0x10246dea0 <nil>  [] 0s} 127.0.0.1 53128 <nil> <nil>}
I1022 01:22:58.315131   64396 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I1022 01:22:58.443368   64396 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I1022 01:22:58.443391   64396 ubuntu.go:71] root file system type: overlay
I1022 01:22:58.443562   64396 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I1022 01:22:58.443766   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:58.509251   64396 main.go:141] libmachine: Using SSH client type: native
I1022 01:22:58.509657   64396 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10246b730] 0x10246dea0 <nil>  [] 0s} 127.0.0.1 53128 <nil> <nil>}
I1022 01:22:58.509709   64396 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I1022 01:22:58.649920   64396 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I1022 01:22:58.650128   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:58.716763   64396 main.go:141] libmachine: Using SSH client type: native
I1022 01:22:58.717159   64396 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10246b730] 0x10246dea0 <nil>  [] 0s} 127.0.0.1 53128 <nil> <nil>}
I1022 01:22:58.717170   64396 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I1022 01:22:58.850852   64396 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I1022 01:22:58.850879   64396 machine.go:91] provisioned docker machine in 1.580030791s
I1022 01:22:58.850893   64396 start.go:300] post-start starting for "minikube" (driver="docker")
I1022 01:22:58.850907   64396 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I1022 01:22:58.851171   64396 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I1022 01:22:58.851285   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:58.916291   64396 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53128 SSHKeyPath:/Users/sinianliu/.minikube/machines/minikube/id_rsa Username:docker}
I1022 01:22:59.013199   64396 ssh_runner.go:195] Run: cat /etc/os-release
I1022 01:22:59.018419   64396 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I1022 01:22:59.018441   64396 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I1022 01:22:59.018448   64396 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I1022 01:22:59.018451   64396 info.go:137] Remote host: Ubuntu 22.04.2 LTS
I1022 01:22:59.018458   64396 filesync.go:126] Scanning /Users/sinianliu/.minikube/addons for local assets ...
I1022 01:22:59.018556   64396 filesync.go:126] Scanning /Users/sinianliu/.minikube/files for local assets ...
I1022 01:22:59.018587   64396 start.go:303] post-start completed in 167.694625ms
I1022 01:22:59.018665   64396 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I1022 01:22:59.018727   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:59.082872   64396 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53128 SSHKeyPath:/Users/sinianliu/.minikube/machines/minikube/id_rsa Username:docker}
I1022 01:22:59.174884   64396 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I1022 01:22:59.182167   64396 fix.go:56] fixHost completed within 1.986675541s
I1022 01:22:59.182175   64396 start.go:83] releasing machines lock for "minikube", held for 1.986887458s
I1022 01:22:59.182260   64396 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1022 01:22:59.246077   64396 ssh_runner.go:195] Run: cat /version.json
I1022 01:22:59.246142   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:59.246756   64396 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I1022 01:22:59.246976   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:22:59.314014   64396 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53128 SSHKeyPath:/Users/sinianliu/.minikube/machines/minikube/id_rsa Username:docker}
I1022 01:22:59.314255   64396 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53128 SSHKeyPath:/Users/sinianliu/.minikube/machines/minikube/id_rsa Username:docker}
I1022 01:22:59.735013   64396 ssh_runner.go:195] Run: systemctl --version
I1022 01:22:59.746302   64396 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I1022 01:22:59.753061   64396 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I1022 01:22:59.778685   64396 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I1022 01:22:59.778862   64396 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I1022 01:22:59.790310   64396 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I1022 01:22:59.790332   64396 start.go:466] detecting cgroup driver to use...
I1022 01:22:59.790359   64396 detect.go:196] detected "cgroupfs" cgroup driver on host os
I1022 01:22:59.791158   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I1022 01:22:59.812398   64396 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I1022 01:22:59.825611   64396 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I1022 01:22:59.838384   64396 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I1022 01:22:59.838504   64396 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I1022 01:22:59.851562   64396 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1022 01:22:59.864245   64396 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I1022 01:22:59.877269   64396 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1022 01:22:59.890170   64396 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I1022 01:22:59.902597   64396 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I1022 01:22:59.915409   64396 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I1022 01:22:59.926665   64396 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I1022 01:22:59.937688   64396 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1022 01:23:00.026443   64396 ssh_runner.go:195] Run: sudo systemctl restart containerd
I1022 01:23:00.131994   64396 start.go:466] detecting cgroup driver to use...
I1022 01:23:00.132015   64396 detect.go:196] detected "cgroupfs" cgroup driver on host os
I1022 01:23:00.132202   64396 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I1022 01:23:00.147526   64396 cruntime.go:276] skipping containerd shutdown because we are bound to it
I1022 01:23:00.147676   64396 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I1022 01:23:00.163226   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I1022 01:23:00.185050   64396 ssh_runner.go:195] Run: which cri-dockerd
I1022 01:23:00.190952   64396 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I1022 01:23:00.203419   64396 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I1022 01:23:00.229536   64396 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I1022 01:23:00.326450   64396 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I1022 01:23:00.418069   64396 docker.go:535] configuring docker to use "cgroupfs" as cgroup driver...
I1022 01:23:00.418088   64396 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I1022 01:23:00.439819   64396 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1022 01:23:00.548639   64396 ssh_runner.go:195] Run: sudo systemctl restart docker
I1022 01:23:00.872992   64396 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I1022 01:23:00.959073   64396 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I1022 01:23:01.043694   64396 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I1022 01:23:01.129623   64396 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1022 01:23:01.220689   64396 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I1022 01:23:01.248923   64396 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1022 01:23:01.332571   64396 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I1022 01:23:01.641090   64396 start.go:513] Will wait 60s for socket path /var/run/cri-dockerd.sock
I1022 01:23:01.642289   64396 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I1022 01:23:01.648765   64396 start.go:534] Will wait 60s for crictl version
I1022 01:23:01.648908   64396 ssh_runner.go:195] Run: which crictl
I1022 01:23:01.654247   64396 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I1022 01:23:01.818422   64396 start.go:550] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.4
RuntimeApiVersion:  v1
I1022 01:23:01.818619   64396 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1022 01:23:01.940625   64396 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1022 01:23:01.975938   64396 out.go:204] 🐳  Preparing Kubernetes v1.27.4 on Docker 24.0.4 ...
I1022 01:23:01.976570   64396 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I1022 01:23:02.152917   64396 network.go:96] got host ip for mount in container by digging dns: 192.168.65.2
I1022 01:23:02.153707   64396 ssh_runner.go:195] Run: grep 192.168.65.2	host.minikube.internal$ /etc/hosts
I1022 01:23:02.159736   64396 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.2	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1022 01:23:02.174471   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1022 01:23:02.238357   64396 preload.go:132] Checking if preload exists for k8s version v1.27.4 and runtime docker
I1022 01:23:02.238437   64396 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1022 01:23:02.264580   64396 docker.go:636] Got preloaded images: -- stdout --
sinianliu/serviceregistry:0.0.1
nginx:latest
registry.k8s.io/kube-apiserver:v1.27.4
registry.k8s.io/kube-controller-manager:v1.27.4
registry.k8s.io/kube-scheduler:v1.27.4
registry.k8s.io/kube-proxy:v1.27.4
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/etcd:3.5.7-0
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I1022 01:23:02.265086   64396 docker.go:566] Images already preloaded, skipping extraction
I1022 01:23:02.265370   64396 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1022 01:23:02.292086   64396 docker.go:636] Got preloaded images: -- stdout --
sinianliu/serviceregistry:0.0.1
nginx:latest
registry.k8s.io/kube-apiserver:v1.27.4
registry.k8s.io/kube-scheduler:v1.27.4
registry.k8s.io/kube-controller-manager:v1.27.4
registry.k8s.io/kube-proxy:v1.27.4
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/etcd:3.5.7-0
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I1022 01:23:02.292104   64396 cache_images.go:84] Images are preloaded, skipping loading
I1022 01:23:02.292195   64396 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I1022 01:23:02.506251   64396 cni.go:84] Creating CNI manager for ""
I1022 01:23:02.506273   64396 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1022 01:23:02.506775   64396 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I1022 01:23:02.506800   64396 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.27.4 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I1022 01:23:02.506989   64396 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.27.4
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I1022 01:23:02.507069   64396 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.27.4/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I1022 01:23:02.507222   64396 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.27.4
I1022 01:23:02.519878   64396 binaries.go:44] Found k8s binaries, skipping transfer
I1022 01:23:02.520023   64396 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I1022 01:23:02.530862   64396 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I1022 01:23:02.551916   64396 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I1022 01:23:02.572624   64396 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2091 bytes)
I1022 01:23:02.594584   64396 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I1022 01:23:02.600103   64396 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1022 01:23:02.614802   64396 certs.go:56] Setting up /Users/sinianliu/.minikube/profiles/minikube for IP: 192.168.49.2
I1022 01:23:02.614845   64396 certs.go:190] acquiring lock for shared ca certs: {Name:mkccdc06cfd0509e4ec592575cbec094163ce5a4 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1022 01:23:02.615377   64396 certs.go:199] skipping minikubeCA CA generation: /Users/sinianliu/.minikube/ca.key
I1022 01:23:02.615684   64396 certs.go:199] skipping proxyClientCA CA generation: /Users/sinianliu/.minikube/proxy-client-ca.key
I1022 01:23:02.615822   64396 certs.go:315] skipping minikube-user signed cert generation: /Users/sinianliu/.minikube/profiles/minikube/client.key
I1022 01:23:02.616155   64396 certs.go:315] skipping minikube signed cert generation: /Users/sinianliu/.minikube/profiles/minikube/apiserver.key.dd3b5fb2
I1022 01:23:02.616531   64396 certs.go:315] skipping aggregator signed cert generation: /Users/sinianliu/.minikube/profiles/minikube/proxy-client.key
I1022 01:23:02.616911   64396 certs.go:437] found cert: /Users/sinianliu/.minikube/certs/Users/sinianliu/.minikube/certs/ca-key.pem (1675 bytes)
I1022 01:23:02.616972   64396 certs.go:437] found cert: /Users/sinianliu/.minikube/certs/Users/sinianliu/.minikube/certs/ca.pem (1086 bytes)
I1022 01:23:02.617029   64396 certs.go:437] found cert: /Users/sinianliu/.minikube/certs/Users/sinianliu/.minikube/certs/cert.pem (1131 bytes)
I1022 01:23:02.617076   64396 certs.go:437] found cert: /Users/sinianliu/.minikube/certs/Users/sinianliu/.minikube/certs/key.pem (1679 bytes)
I1022 01:23:02.619213   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I1022 01:23:02.647855   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I1022 01:23:02.675892   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I1022 01:23:02.704338   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I1022 01:23:02.732237   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I1022 01:23:02.760565   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I1022 01:23:02.788307   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I1022 01:23:02.816036   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I1022 01:23:02.843773   64396 ssh_runner.go:362] scp /Users/sinianliu/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I1022 01:23:02.871985   64396 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I1022 01:23:02.894294   64396 ssh_runner.go:195] Run: openssl version
I1022 01:23:02.906674   64396 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I1022 01:23:02.920986   64396 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I1022 01:23:02.926434   64396 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Oct 15 09:13 /usr/share/ca-certificates/minikubeCA.pem
I1022 01:23:02.926481   64396 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I1022 01:23:02.935862   64396 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I1022 01:23:02.948057   64396 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I1022 01:23:02.953305   64396 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I1022 01:23:02.963102   64396 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I1022 01:23:02.972728   64396 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I1022 01:23:02.982012   64396 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I1022 01:23:02.991265   64396 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I1022 01:23:03.000298   64396 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I1022 01:23:03.009924   64396 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I1022 01:23:03.010486   64396 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I1022 01:23:03.038814   64396 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I1022 01:23:03.051438   64396 kubeadm.go:419] found existing configuration files, will attempt cluster restart
I1022 01:23:03.051773   64396 kubeadm.go:636] restartCluster start
I1022 01:23:03.051932   64396 ssh_runner.go:195] Run: sudo test -d /data/minikube
I1022 01:23:03.062757   64396 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I1022 01:23:03.062900   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1022 01:23:03.132997   64396 kubeconfig.go:92] found "minikube" server: "https://127.0.0.1:52870"
I1022 01:23:03.133016   64396 kubeconfig.go:135] verify returned: got: 127.0.0.1:52870, want: 127.0.0.1:53132
I1022 01:23:03.133403   64396 lock.go:35] WriteFile acquiring /Users/sinianliu/.kube/config: {Name:mk89a90b5df25e589b4610d3d8c5739c0c387cbc Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1022 01:23:03.141034   64396 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I1022 01:23:03.153124   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:03.153224   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:03.166685   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:03.166693   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:03.166762   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:03.178851   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:03.680112   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:03.680653   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:03.713629   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:04.179923   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:04.180352   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:04.194680   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:04.680039   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:04.680472   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:04.713625   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:05.179973   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:05.180356   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:05.215233   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:05.679546   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:05.679946   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:05.706721   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:06.179888   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:06.180130   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:06.210154   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:06.679867   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:06.680369   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:06.713750   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:07.179680   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:07.180167   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:07.212517   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:07.679805   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:07.680156   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:07.708614   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:08.179852   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:08.180142   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:08.210196   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:08.679789   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:08.680243   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:08.708734   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:09.179015   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:09.179448   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:09.211933   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:09.679773   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:09.680152   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:09.709178   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:10.179756   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:10.180103   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:10.205726   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:10.679190   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:10.679615   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:10.710195   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:11.179640   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:11.180155   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:11.205963   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:11.678865   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:11.679383   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:11.706948   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:12.178979   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:12.179236   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:12.210418   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:12.678604   64396 api_server.go:166] Checking apiserver status ...
I1022 01:23:12.678991   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W1022 01:23:12.705188   64396 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I1022 01:23:13.153561   64396 kubeadm.go:611] needs reconfigure: apiserver error: context deadline exceeded
I1022 01:23:13.153604   64396 kubeadm.go:1128] stopping kube-system containers ...
I1022 01:23:13.153843   64396 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I1022 01:23:13.194824   64396 docker.go:462] Stopping containers: [c421faf19561 6a75ceb4c7d5 a49af6023c9f fb885071eab5 bae908757963 bc256f3b6279 28ab2c120f4a 7bf865bf516b da6aa7eea63e 36dcbf7d8cf8 66cf9747210a 96a1fb15ee04 3c2914e00730 59bd79e794ec f963e5a58b75]
I1022 01:23:13.194951   64396 ssh_runner.go:195] Run: docker stop c421faf19561 6a75ceb4c7d5 a49af6023c9f fb885071eab5 bae908757963 bc256f3b6279 28ab2c120f4a 7bf865bf516b da6aa7eea63e 36dcbf7d8cf8 66cf9747210a 96a1fb15ee04 3c2914e00730 59bd79e794ec f963e5a58b75
I1022 01:23:13.222056   64396 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I1022 01:23:13.237926   64396 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I1022 01:23:13.250235   64396 kubeadm.go:155] found existing configuration files:
-rw------- 1 root root 5643 Oct 15 09:13 /etc/kubernetes/admin.conf
-rw------- 1 root root 5656 Oct 15 09:13 /etc/kubernetes/controller-manager.conf
-rw------- 1 root root 1971 Oct 15 09:13 /etc/kubernetes/kubelet.conf
-rw------- 1 root root 5600 Oct 15 09:13 /etc/kubernetes/scheduler.conf

I1022 01:23:13.250416   64396 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I1022 01:23:13.262299   64396 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I1022 01:23:13.275281   64396 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I1022 01:23:13.287554   64396 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 1
stdout:

stderr:
I1022 01:23:13.287793   64396 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I1022 01:23:13.299151   64396 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I1022 01:23:13.311166   64396 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 1
stdout:

stderr:
I1022 01:23:13.311330   64396 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I1022 01:23:13.322466   64396 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I1022 01:23:13.334251   64396 kubeadm.go:713] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I1022 01:23:13.334271   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I1022 01:23:13.505688   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I1022 01:23:15.167845   64396 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml": (1.662176125s)
I1022 01:23:15.167880   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I1022 01:23:15.325047   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I1022 01:23:15.385593   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I1022 01:23:15.446720   64396 api_server.go:52] waiting for apiserver process to appear ...
I1022 01:23:15.446893   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1022 01:23:15.460594   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1022 01:23:15.976748   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1022 01:23:16.475850   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1022 01:23:16.976869   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1022 01:23:17.006517   64396 api_server.go:72] duration metric: took 1.559846875s to wait for apiserver process to appear ...
I1022 01:23:17.006532   64396 api_server.go:88] waiting for apiserver healthz status ...
I1022 01:23:17.006593   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:17.012503   64396 api_server.go:269] stopped: https://127.0.0.1:53132/healthz: Get "https://127.0.0.1:53132/healthz": EOF
I1022 01:23:17.012527   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:17.014707   64396 api_server.go:269] stopped: https://127.0.0.1:53132/healthz: Get "https://127.0.0.1:53132/healthz": EOF
I1022 01:23:17.515807   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:17.517976   64396 api_server.go:269] stopped: https://127.0.0.1:53132/healthz: Get "https://127.0.0.1:53132/healthz": EOF
I1022 01:23:18.015789   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:20.071956   64396 api_server.go:279] https://127.0.0.1:53132/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W1022 01:23:20.071977   64396 api_server.go:103] status: https://127.0.0.1:53132/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I1022 01:23:20.071993   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:20.164616   64396 api_server.go:279] https://127.0.0.1:53132/healthz returned 500:
[+]ping ok
[+]log ok
[-]etcd failed: reason withheld
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[+]poststarthook/start-system-namespaces-controller ok
[-]poststarthook/bootstrap-controller failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/priority-and-fairness-config-producer failed: reason withheld
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[-]poststarthook/apiservice-registration-controller failed: reason withheld
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W1022 01:23:20.164647   64396 api_server.go:103] status: https://127.0.0.1:53132/healthz returned error 500:
[+]ping ok
[+]log ok
[-]etcd failed: reason withheld
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[+]poststarthook/start-system-namespaces-controller ok
[-]poststarthook/bootstrap-controller failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/priority-and-fairness-config-producer failed: reason withheld
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[-]poststarthook/apiservice-registration-controller failed: reason withheld
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I1022 01:23:20.514890   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:20.533974   64396 api_server.go:279] https://127.0.0.1:53132/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W1022 01:23:20.534001   64396 api_server.go:103] status: https://127.0.0.1:53132/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I1022 01:23:21.014806   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:21.021643   64396 api_server.go:279] https://127.0.0.1:53132/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W1022 01:23:21.021665   64396 api_server.go:103] status: https://127.0.0.1:53132/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I1022 01:23:21.514798   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:21.567776   64396 api_server.go:279] https://127.0.0.1:53132/healthz returned 200:
ok
I1022 01:23:21.580903   64396 api_server.go:141] control plane version: v1.27.4
I1022 01:23:21.580920   64396 api_server.go:131] duration metric: took 4.574531125s to wait for apiserver health ...
I1022 01:23:21.580927   64396 cni.go:84] Creating CNI manager for ""
I1022 01:23:21.580939   64396 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1022 01:23:21.585361   64396 out.go:177] 🔗  Configuring bridge CNI (Container Networking Interface) ...
I1022 01:23:21.589676   64396 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I1022 01:23:21.608166   64396 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I1022 01:23:21.679446   64396 system_pods.go:43] waiting for kube-system pods to appear ...
I1022 01:23:21.691927   64396 system_pods.go:59] 7 kube-system pods found
I1022 01:23:21.691948   64396 system_pods.go:61] "coredns-5d78c9869d-rfsxg" [7d3cc1d8-1739-46ef-b15c-a53f09f53f33] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I1022 01:23:21.691957   64396 system_pods.go:61] "etcd-minikube" [72a06061-669a-483f-8e2f-acf80354be27] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I1022 01:23:21.691969   64396 system_pods.go:61] "kube-apiserver-minikube" [b1489acc-665b-40ba-9156-82c97846d88d] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I1022 01:23:21.691976   64396 system_pods.go:61] "kube-controller-manager-minikube" [7f3f793a-5437-4e89-aa73-2cfb03b12e56] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I1022 01:23:21.691983   64396 system_pods.go:61] "kube-proxy-cl7h2" [21cfa4d9-8fe3-4340-a281-c0c25c38e2ee] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I1022 01:23:21.691989   64396 system_pods.go:61] "kube-scheduler-minikube" [ad07944b-0c29-4248-8b76-7924b2a729fe] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I1022 01:23:21.691995   64396 system_pods.go:61] "storage-provisioner" [fc88c1ed-1c85-48fc-b619-37cb94022881] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I1022 01:23:21.692001   64396 system_pods.go:74] duration metric: took 12.545166ms to wait for pod list to return data ...
I1022 01:23:21.692008   64396 node_conditions.go:102] verifying NodePressure condition ...
I1022 01:23:21.701479   64396 node_conditions.go:122] node storage ephemeral capacity is 61202244Ki
I1022 01:23:21.701496   64396 node_conditions.go:123] node cpu capacity is 4
I1022 01:23:21.701506   64396 node_conditions.go:105] duration metric: took 9.493417ms to run NodePressure ...
I1022 01:23:21.701524   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I1022 01:23:22.083043   64396 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I1022 01:23:22.103358   64396 ops.go:34] apiserver oom_adj: -16
I1022 01:23:22.103370   64396 kubeadm.go:640] restartCluster took 19.05233325s
I1022 01:23:22.103377   64396 kubeadm.go:406] StartCluster complete in 19.09420075s
I1022 01:23:22.103394   64396 settings.go:142] acquiring lock: {Name:mk9271d89dcd55c0800c60a58a6d2d95406c58c8 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1022 01:23:22.104317   64396 settings.go:150] Updating kubeconfig:  /Users/sinianliu/.kube/config
I1022 01:23:22.105817   64396 lock.go:35] WriteFile acquiring /Users/sinianliu/.kube/config: {Name:mk89a90b5df25e589b4610d3d8c5739c0c387cbc Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1022 01:23:22.106682   64396 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I1022 01:23:22.106750   64396 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.27.4/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I1022 01:23:22.106760   64396 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false]
I1022 01:23:22.107105   64396 addons.go:69] Setting default-storageclass=true in profile "minikube"
I1022 01:23:22.107105   64396 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I1022 01:23:22.107117   64396 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I1022 01:23:22.107121   64396 addons.go:231] Setting addon storage-provisioner=true in "minikube"
W1022 01:23:22.107126   64396 addons.go:240] addon storage-provisioner should already be in state true
I1022 01:23:22.107365   64396 host.go:66] Checking if "minikube" exists ...
I1022 01:23:22.107689   64396 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1022 01:23:22.107833   64396 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1022 01:23:22.119171   64396 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I1022 01:23:22.119209   64396 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}
I1022 01:23:22.124565   64396 out.go:177] 🔎  Verifying Kubernetes components...
I1022 01:23:22.132448   64396 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I1022 01:23:22.297508   64396 out.go:177]     ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I1022 01:23:22.301262   64396 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I1022 01:23:22.301269   64396 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I1022 01:23:22.301355   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:23:22.303499   64396 addons.go:231] Setting addon default-storageclass=true in "minikube"
W1022 01:23:22.303516   64396 addons.go:240] addon default-storageclass should already be in state true
I1022 01:23:22.303534   64396 host.go:66] Checking if "minikube" exists ...
I1022 01:23:22.303970   64396 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1022 01:23:22.377810   64396 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I1022 01:23:22.377828   64396 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I1022 01:23:22.377991   64396 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53128 SSHKeyPath:/Users/sinianliu/.minikube/machines/minikube/id_rsa Username:docker}
I1022 01:23:22.377996   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1022 01:23:22.448537   64396 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53128 SSHKeyPath:/Users/sinianliu/.minikube/machines/minikube/id_rsa Username:docker}
I1022 01:23:22.587533   64396 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.4/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I1022 01:23:22.608231   64396 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.4/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I1022 01:23:22.888268   64396 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1022 01:23:22.889434   64396 start.go:874] CoreDNS already contains "host.minikube.internal" host record, skipping...
I1022 01:23:22.966612   64396 api_server.go:52] waiting for apiserver process to appear ...
I1022 01:23:22.966818   64396 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1022 01:23:23.789137   64396 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.4/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (1.201594083s)
I1022 01:23:23.789193   64396 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.4/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (1.180960875s)
I1022 01:23:23.789231   64396 api_server.go:72] duration metric: took 1.670052208s to wait for apiserver process to appear ...
I1022 01:23:23.789244   64396 api_server.go:88] waiting for apiserver healthz status ...
I1022 01:23:23.789267   64396 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:53132/healthz ...
I1022 01:23:23.798170   64396 out.go:177] 🌟  Enabled addons: storage-provisioner, default-storageclass
I1022 01:23:23.795698   64396 api_server.go:279] https://127.0.0.1:53132/healthz returned 200:
ok
I1022 01:23:23.802180   64396 addons.go:502] enable addons completed in 1.695492334s: enabled=[storage-provisioner default-storageclass]
I1022 01:23:23.799471   64396 api_server.go:141] control plane version: v1.27.4
I1022 01:23:23.802203   64396 api_server.go:131] duration metric: took 12.951333ms to wait for apiserver health ...
I1022 01:23:23.802212   64396 system_pods.go:43] waiting for kube-system pods to appear ...
I1022 01:23:23.807887   64396 system_pods.go:59] 7 kube-system pods found
I1022 01:23:23.807910   64396 system_pods.go:61] "coredns-5d78c9869d-rfsxg" [7d3cc1d8-1739-46ef-b15c-a53f09f53f33] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I1022 01:23:23.807924   64396 system_pods.go:61] "etcd-minikube" [72a06061-669a-483f-8e2f-acf80354be27] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I1022 01:23:23.807939   64396 system_pods.go:61] "kube-apiserver-minikube" [b1489acc-665b-40ba-9156-82c97846d88d] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I1022 01:23:23.807951   64396 system_pods.go:61] "kube-controller-manager-minikube" [7f3f793a-5437-4e89-aa73-2cfb03b12e56] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I1022 01:23:23.807956   64396 system_pods.go:61] "kube-proxy-cl7h2" [21cfa4d9-8fe3-4340-a281-c0c25c38e2ee] Running
I1022 01:23:23.807963   64396 system_pods.go:61] "kube-scheduler-minikube" [ad07944b-0c29-4248-8b76-7924b2a729fe] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I1022 01:23:23.807968   64396 system_pods.go:61] "storage-provisioner" [fc88c1ed-1c85-48fc-b619-37cb94022881] Running
I1022 01:23:23.807972   64396 system_pods.go:74] duration metric: took 5.753833ms to wait for pod list to return data ...
I1022 01:23:23.807980   64396 kubeadm.go:581] duration metric: took 1.688809583s to wait for : map[apiserver:true system_pods:true] ...
I1022 01:23:23.807991   64396 node_conditions.go:102] verifying NodePressure condition ...
I1022 01:23:23.810223   64396 node_conditions.go:122] node storage ephemeral capacity is 61202244Ki
I1022 01:23:23.810230   64396 node_conditions.go:123] node cpu capacity is 4
I1022 01:23:23.810239   64396 node_conditions.go:105] duration metric: took 2.243958ms to run NodePressure ...
I1022 01:23:23.810250   64396 start.go:228] waiting for startup goroutines ...
I1022 01:23:23.810256   64396 start.go:233] waiting for cluster config update ...
I1022 01:23:23.810268   64396 start.go:242] writing updated cluster config ...
I1022 01:23:23.813919   64396 ssh_runner.go:195] Run: rm -f paused
I1022 01:23:23.914853   64396 start.go:600] kubectl: 1.28.2, cluster: 1.27.4 (minor skew: 1)
I1022 01:23:23.919206   64396 out.go:177] 🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* Oct 22 17:19:33 minikube dockerd[847]: time="2023-10-22T17:19:33.829671054Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:19:33 minikube dockerd[847]: time="2023-10-22T17:19:33.829804262Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:19:40 minikube dockerd[847]: time="2023-10-22T17:19:40.783077334Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:19:40 minikube dockerd[847]: time="2023-10-22T17:19:40.783862084Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:20:52 minikube dockerd[847]: time="2023-10-22T17:20:52.395683173Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:20:54 minikube dockerd[847]: time="2023-10-22T17:20:54.087754132Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:20:57 minikube dockerd[847]: time="2023-10-22T17:20:57.211982717Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:20:57 minikube dockerd[847]: time="2023-10-22T17:20:57.213285175Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:20:58 minikube dockerd[847]: time="2023-10-22T17:20:58.525178634Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:20:58 minikube dockerd[847]: time="2023-10-22T17:20:58.525324509Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:21:04 minikube dockerd[847]: time="2023-10-22T17:21:04.079320345Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:21:04 minikube dockerd[847]: time="2023-10-22T17:21:04.079439762Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:23:38 minikube dockerd[847]: time="2023-10-22T17:23:38.846501833Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:23:39 minikube dockerd[847]: time="2023-10-22T17:23:39.903467709Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:23:39 minikube dockerd[847]: time="2023-10-22T17:23:39.903531792Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:23:40 minikube dockerd[847]: time="2023-10-22T17:23:40.939510834Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:23:50 minikube dockerd[847]: time="2023-10-22T17:23:50.777957547Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:23:50 minikube dockerd[847]: time="2023-10-22T17:23:50.778012381Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:23:59 minikube dockerd[847]: time="2023-10-22T17:23:59.803510677Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:23:59 minikube dockerd[847]: time="2023-10-22T17:23:59.803593343Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:31:40 minikube dockerd[847]: time="2023-10-22T17:31:40.865998046Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:31:40 minikube dockerd[847]: time="2023-10-22T17:31:40.866193880Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:31:42 minikube dockerd[847]: time="2023-10-22T17:31:42.223831172Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:31:44 minikube dockerd[847]: time="2023-10-22T17:31:44.931897090Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:31:52 minikube dockerd[847]: time="2023-10-22T17:31:52.402033343Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:31:52 minikube dockerd[847]: time="2023-10-22T17:31:52.402168052Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:31:56 minikube dockerd[847]: time="2023-10-22T17:31:56.399794929Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:31:56 minikube dockerd[847]: time="2023-10-22T17:31:56.401241720Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:49:53 minikube dockerd[847]: time="2023-10-22T17:49:53.109690965Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:50:03 minikube dockerd[847]: time="2023-10-22T17:50:03.119063386Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:50:03 minikube dockerd[847]: time="2023-10-22T17:50:03.119889928Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:50:07 minikube dockerd[847]: time="2023-10-22T17:50:07.219083721Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:50:13 minikube dockerd[847]: time="2023-10-22T17:50:13.912312044Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:50:13 minikube dockerd[847]: time="2023-10-22T17:50:13.912495419Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:50:17 minikube dockerd[847]: time="2023-10-22T17:50:17.068539378Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:50:17 minikube dockerd[847]: time="2023-10-22T17:50:17.068661795Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:54:59 minikube dockerd[847]: time="2023-10-22T17:54:59.976422176Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:55:14 minikube dockerd[847]: time="2023-10-22T17:55:14.084950169Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:55:14 minikube dockerd[847]: time="2023-10-22T17:55:14.085056294Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:55:17 minikube dockerd[847]: time="2023-10-22T17:55:17.059276920Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:55:17 minikube dockerd[847]: time="2023-10-22T17:55:17.059377337Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 17:55:18 minikube dockerd[847]: time="2023-10-22T17:55:18.457228254Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 17:55:29 minikube dockerd[847]: time="2023-10-22T17:55:29.990622676Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 17:55:29 minikube dockerd[847]: time="2023-10-22T17:55:29.991347885Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 18:00:12 minikube dockerd[847]: time="2023-10-22T18:00:12.418423835Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 18:00:18 minikube dockerd[847]: time="2023-10-22T18:00:18.118158296Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 18:00:18 minikube dockerd[847]: time="2023-10-22T18:00:18.118890379Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 18:00:30 minikube dockerd[847]: time="2023-10-22T18:00:30.120811676Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 18:00:30 minikube dockerd[847]: time="2023-10-22T18:00:30.121300343Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 18:00:31 minikube dockerd[847]: time="2023-10-22T18:00:31.501711177Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 18:00:35 minikube dockerd[847]: time="2023-10-22T18:00:35.876432096Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 18:00:35 minikube dockerd[847]: time="2023-10-22T18:00:35.876545387Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 18:05:14 minikube dockerd[847]: time="2023-10-22T18:05:14.124535544Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 18:05:29 minikube dockerd[847]: time="2023-10-22T18:05:29.950781135Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 18:05:29 minikube dockerd[847]: time="2023-10-22T18:05:29.952404676Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 18:05:31 minikube dockerd[847]: time="2023-10-22T18:05:31.781709719Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 18:05:31 minikube dockerd[847]: time="2023-10-22T18:05:31.781831260Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Oct 22 18:05:35 minikube dockerd[847]: time="2023-10-22T18:05:35.214716179Z" level=error msg="Not continuing with pull after error: manifest unknown: manifest unknown"
Oct 22 18:05:42 minikube dockerd[847]: time="2023-10-22T18:05:42.978836668Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Oct 22 18:05:42 minikube dockerd[847]: time="2023-10-22T18:05:42.980679043Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                                  CREATED             STATE               NAME                        ATTEMPT             POD ID              POD
1b70ac0fa4432       redis@sha256:1f1bd4adf5dabf173b235ba373faef55f3ad53394791d1473763bf5a2181780d                          51 minutes ago      Running             redis-app                   0                   0d4c01ff2683b       redis-app-75474c45c-fjm94
a73f911e8b867       kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c   58 minutes ago      Running             dashboard-metrics-scraper   0                   36996d1d325d6       dashboard-metrics-scraper-5dd9cbfd69-2fl69
99e010e50d662       kubernetesui/dashboard@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93         58 minutes ago      Running             kubernetes-dashboard        0                   6b19bfd55d2fe       kubernetes-dashboard-5c5cfc8747-6b2mh
34c587b33a9fb       ba04bb24b9575                                                                                          10 hours ago        Running             storage-provisioner         3                   8c4552dbffb00       storage-provisioner
689eaa3b9f972       sinianliu/serviceregistry@sha256:773230d1020023f44abf7949c712c79a36a90fb0a2f8eb9b1cd8f23f1b448381      10 hours ago        Running             service-registry            1                   57a2b158829c0       service-registry-69c6c987f8-cs8ff
79bccfc69fe4a       nginx@sha256:b4af4f8b6470febf45dc10f564551af682a802eda1743055a7dfc8332dffa595                          10 hours ago        Running             nginx                       1                   2fbccee08a417       nginx-77b4fdf86c-xgdlk
6676a2be49d81       97e04611ad434                                                                                          10 hours ago        Running             coredns                     1                   327cd13dfe210       coredns-5d78c9869d-rfsxg
6ddc40bc591f8       532e5a30e948f                                                                                          10 hours ago        Running             kube-proxy                  1                   53a73f001b91f       kube-proxy-cl7h2
1737bfc2a66b5       ba04bb24b9575                                                                                          10 hours ago        Exited              storage-provisioner         2                   8c4552dbffb00       storage-provisioner
65b91120efb62       24bc64e911039                                                                                          10 hours ago        Running             etcd                        1                   7baf786e85923       etcd-minikube
283915b50eb36       389f6f052cf83                                                                                          10 hours ago        Running             kube-controller-manager     1                   91a6bc7a1103e       kube-controller-manager-minikube
d029e09f61131       6eb63895cb67f                                                                                          10 hours ago        Running             kube-scheduler              1                   1e2983a46a3c1       kube-scheduler-minikube
b783d326de45d       64aece92d6bde                                                                                          10 hours ago        Running             kube-apiserver              1                   22225e36a38ff       kube-apiserver-minikube
eb0236a8377e1       sinianliu/serviceregistry@sha256:773230d1020023f44abf7949c712c79a36a90fb0a2f8eb9b1cd8f23f1b448381      6 days ago          Exited              service-registry            0                   2bde02fe228cd       service-registry-69c6c987f8-cs8ff
f8d527ed65945       nginx@sha256:b4af4f8b6470febf45dc10f564551af682a802eda1743055a7dfc8332dffa595                          6 days ago          Exited              nginx                       0                   0a53e22ec61d4       nginx-77b4fdf86c-xgdlk
6a75ceb4c7d5f       97e04611ad434                                                                                          7 days ago          Exited              coredns                     0                   a49af6023c9f0       coredns-5d78c9869d-rfsxg
bae9087579630       532e5a30e948f                                                                                          7 days ago          Exited              kube-proxy                  0                   28ab2c120f4ad       kube-proxy-cl7h2
7bf865bf516ba       24bc64e911039                                                                                          7 days ago          Exited              etcd                        0                   f963e5a58b755       etcd-minikube
da6aa7eea63e0       6eb63895cb67f                                                                                          7 days ago          Exited              kube-scheduler              0                   96a1fb15ee042       kube-scheduler-minikube
36dcbf7d8cf8b       389f6f052cf83                                                                                          7 days ago          Exited              kube-controller-manager     0                   3c2914e00730a       kube-controller-manager-minikube
66cf9747210a7       64aece92d6bde                                                                                          7 days ago          Exited              kube-apiserver              0                   59bd79e794ec5       kube-apiserver-minikube

* 
* ==> coredns [6676a2be49d8] <==
* [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 8846d9ca81164c00fa03e78dfcf1a6846552cc49335bc010218794b8cfaf537759aa4b596e7dc20c0f618e8eb07603c0139662b99dfa3de45b176fbe7fb57ce1
CoreDNS-1.10.1
linux/arm64, go1.20, 055b2c3
[INFO] 127.0.0.1:54314 - 59245 "HINFO IN 4078414366965079763.8143220224011904154. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.082333291s

* 
* ==> coredns [6a75ceb4c7d5] <==
* [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 8846d9ca81164c00fa03e78dfcf1a6846552cc49335bc010218794b8cfaf537759aa4b596e7dc20c0f618e8eb07603c0139662b99dfa3de45b176fbe7fb57ce1
CoreDNS-1.10.1
linux/arm64, go1.20, 055b2c3
[INFO] 127.0.0.1:56974 - 50321 "HINFO IN 1429426997555557132.2740313134251385787. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.080421625s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=arm64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=arm64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=fd7ecd9c4599bef9f04c0986c4a0187f98a4396e
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_10_15T02_13_43_0700
                    minikube.k8s.io/version=v1.31.2
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sun, 15 Oct 2023 09:13:40 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Sun, 22 Oct 2023 18:09:58 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Sun, 22 Oct 2023 18:05:10 +0000   Sun, 15 Oct 2023 09:13:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Sun, 22 Oct 2023 18:05:10 +0000   Sun, 15 Oct 2023 09:13:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Sun, 22 Oct 2023 18:05:10 +0000   Sun, 15 Oct 2023 09:13:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Sun, 22 Oct 2023 18:05:10 +0000   Sun, 15 Oct 2023 09:13:40 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  61202244Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             8040056Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  61202244Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             8040056Ki
  pods:               110
System Info:
  Machine ID:                 d5afc5bf5b33475cb2a06ab85f805101
  System UUID:                d5afc5bf5b33475cb2a06ab85f805101
  Boot ID:                    f9d5c084-8c27-45b2-bf21-c0eee8d51233
  Kernel Version:             5.15.49-linuxkit
  OS Image:                   Ubuntu 22.04.2 LTS
  Operating System:           linux
  Architecture:               arm64
  Container Runtime Version:  docker://24.0.4
  Kubelet Version:            v1.27.4
  Kube-Proxy Version:         v1.27.4
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (17 in total)
  Namespace                   Name                                          CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                          ------------  ----------  ---------------  -------------  ---
  default                     cloud-gateway-app-684b844c64-7pw68            0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         52m
  default                     config-server-app-57bf8b9f8f-nqgm9            0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         52m
  default                     nginx-77b4fdf86c-xgdlk                        0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         6d22h
  default                     order-service-app-6c98f7fd45-sks5h            0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         52m
  default                     payment-service-app-c544599f6-wl8dq           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         52m
  default                     product-service-app-77b9cbc65d-77zff          0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         52m
  default                     redis-app-75474c45c-fjm94                     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         52m
  kube-system                 coredns-5d78c9869d-rfsxg                      100m (2%!)(MISSING)     0 (0%!)(MISSING)      70Mi (0%!)(MISSING)        170Mi (2%!)(MISSING)     7d8h
  kube-system                 etcd-minikube                                 100m (2%!)(MISSING)     0 (0%!)(MISSING)      100Mi (1%!)(MISSING)       0 (0%!)(MISSING)         7d8h
  kube-system                 kube-apiserver-minikube                       250m (6%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d8h
  kube-system                 kube-controller-manager-minikube              200m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d8h
  kube-system                 kube-proxy-cl7h2                              0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d8h
  kube-system                 kube-scheduler-minikube                       100m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d8h
  kube-system                 storage-provisioner                           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d8h
  kubernetes-dashboard        dashboard-metrics-scraper-5dd9cbfd69-2fl69    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         59m
  kubernetes-dashboard        kubernetes-dashboard-5c5cfc8747-6b2mh         0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         59m
  microservices               service-registry-69c6c987f8-cs8ff             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         6d19h
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (18%!)(MISSING)  0 (0%!)(MISSING)
  memory             170Mi (2%!)(MISSING)  170Mi (2%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-32Mi     0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-64Ki     0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age              From             Message
  ----    ------                   ----             ----             -------
  Normal  Starting                 9h               kube-proxy       
  Normal  Starting                 9h               kubelet          Starting kubelet.
  Normal  NodeHasSufficientMemory  9h (x8 over 9h)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    9h (x8 over 9h)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     9h (x7 over 9h)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  9h               kubelet          Updated Node Allocatable limit across pods
  Normal  RegisteredNode           9h               node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [Oct21 18:48] cacheinfo: Unable to detect cache hierarchy for CPU 0
[  +0.012812] the cryptoloop driver has been deprecated and will be removed in in Linux 5.16
[  +0.018282] device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
[  +5.120904] grpcfuse: loading out-of-tree module taints kernel.
[Oct22 05:46] hrtimer: interrupt took 3781959 ns

* 
* ==> etcd [65b91120efb6] <==
* {"level":"info","ts":"2023-10-22T08:23:17.495Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-10-22T08:23:17.497Z","caller":"etcdserver/corrupt.go:95","msg":"starting initial corruption check","local-member-id":"aec36adc501070cc","timeout":"7s"}
{"level":"info","ts":"2023-10-22T08:23:17.498Z","caller":"etcdserver/corrupt.go:165","msg":"initial corruption checking passed; no corruption","local-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2023-10-22T08:23:17.498Z","caller":"etcdserver/server.go:845","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.7","cluster-id":"fa54960ea34d58be","cluster-version":"3.5"}
{"level":"info","ts":"2023-10-22T08:23:17.500Z","caller":"etcdserver/server.go:738","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2023-10-22T08:23:17.500Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2023-10-22T08:23:17.500Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2023-10-22T08:23:17.501Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2023-10-22T08:23:17.504Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-10-22T08:23:17.504Z","caller":"embed/etcd.go:275","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-10-22T08:23:17.504Z","caller":"embed/etcd.go:586","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-10-22T08:23:17.504Z","caller":"embed/etcd.go:558","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-10-22T08:23:17.504Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-10-22T08:23:18.487Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 2"}
{"level":"info","ts":"2023-10-22T08:23:18.487Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 2"}
{"level":"info","ts":"2023-10-22T08:23:18.487Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2023-10-22T08:23:18.487Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 3"}
{"level":"info","ts":"2023-10-22T08:23:18.487Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 3"}
{"level":"info","ts":"2023-10-22T08:23:18.487Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 3"}
{"level":"info","ts":"2023-10-22T08:23:18.487Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 3"}
{"level":"info","ts":"2023-10-22T08:23:18.490Z","caller":"etcdserver/server.go:2062","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2023-10-22T08:23:18.490Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-10-22T08:23:18.490Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-10-22T08:23:18.494Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"192.168.49.2:2379"}
{"level":"info","ts":"2023-10-22T08:23:18.497Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2023-10-22T08:23:18.497Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2023-10-22T08:23:18.506Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-10-22T17:06:24.017Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":22569}
{"level":"info","ts":"2023-10-22T17:06:24.044Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":22569,"took":"23.912292ms","hash":1796451596}
{"level":"info","ts":"2023-10-22T17:06:24.044Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1796451596,"revision":22569,"compact-revision":21765}
{"level":"info","ts":"2023-10-22T17:13:27.672Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":22808}
{"level":"info","ts":"2023-10-22T17:13:27.675Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":22808,"took":"1.908375ms","hash":1440864356}
{"level":"info","ts":"2023-10-22T17:13:27.675Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1440864356,"revision":22808,"compact-revision":22569}
{"level":"info","ts":"2023-10-22T17:18:27.679Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":23129}
{"level":"info","ts":"2023-10-22T17:18:27.683Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":23129,"took":"2.410584ms","hash":3048601308}
{"level":"info","ts":"2023-10-22T17:18:27.683Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3048601308,"revision":23129,"compact-revision":22808}
{"level":"info","ts":"2023-10-22T17:23:27.686Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":23587}
{"level":"info","ts":"2023-10-22T17:23:27.689Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":23587,"took":"2.412958ms","hash":1876392894}
{"level":"info","ts":"2023-10-22T17:23:27.689Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1876392894,"revision":23587,"compact-revision":23129}
{"level":"info","ts":"2023-10-22T17:28:37.172Z","caller":"etcdserver/server.go:1395","msg":"triggering snapshot","local-member-id":"aec36adc501070cc","local-member-applied-index":30003,"local-member-snapshot-index":20002,"local-member-snapshot-count":10000}
{"level":"info","ts":"2023-10-22T17:28:37.181Z","caller":"etcdserver/server.go:2413","msg":"saved snapshot","snapshot-index":30003}
{"level":"info","ts":"2023-10-22T17:28:37.181Z","caller":"etcdserver/server.go:2443","msg":"compacted Raft logs","compact-index":25003}
{"level":"info","ts":"2023-10-22T17:31:19.930Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":23954}
{"level":"info","ts":"2023-10-22T17:31:19.936Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":23954,"took":"3.634083ms","hash":4287340726}
{"level":"info","ts":"2023-10-22T17:31:19.936Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":4287340726,"revision":23954,"compact-revision":23587}
{"level":"info","ts":"2023-10-22T17:49:28.562Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":24221}
{"level":"info","ts":"2023-10-22T17:49:28.564Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":24221,"took":"1.693ms","hash":1235623427}
{"level":"info","ts":"2023-10-22T17:49:28.564Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1235623427,"revision":24221,"compact-revision":23954}
{"level":"info","ts":"2023-10-22T17:54:28.559Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":24478}
{"level":"info","ts":"2023-10-22T17:54:28.562Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":24478,"took":"1.720542ms","hash":1402697006}
{"level":"info","ts":"2023-10-22T17:54:28.562Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1402697006,"revision":24478,"compact-revision":24221}
{"level":"info","ts":"2023-10-22T17:59:28.560Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":24733}
{"level":"info","ts":"2023-10-22T17:59:28.563Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":24733,"took":"2.51225ms","hash":1456606373}
{"level":"info","ts":"2023-10-22T17:59:28.563Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1456606373,"revision":24733,"compact-revision":24478}
{"level":"info","ts":"2023-10-22T18:04:28.558Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":24989}
{"level":"info","ts":"2023-10-22T18:04:28.562Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":24989,"took":"2.622041ms","hash":221054683}
{"level":"info","ts":"2023-10-22T18:04:28.562Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":221054683,"revision":24989,"compact-revision":24733}
{"level":"info","ts":"2023-10-22T18:09:28.558Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":25243}
{"level":"info","ts":"2023-10-22T18:09:28.562Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":25243,"took":"2.755666ms","hash":1372801032}
{"level":"info","ts":"2023-10-22T18:09:28.562Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1372801032,"revision":25243,"compact-revision":24989}

* 
* ==> etcd [7bf865bf516b] <==
* {"level":"info","ts":"2023-10-16T17:47:01.494Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":17214,"took":"1.707709ms","hash":1887955663}
{"level":"info","ts":"2023-10-16T17:47:01.494Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1887955663,"revision":17214,"compact-revision":16974}
{"level":"info","ts":"2023-10-16T17:52:01.512Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":17453}
{"level":"info","ts":"2023-10-16T17:52:01.517Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":17453,"took":"3.442625ms","hash":3877123307}
{"level":"info","ts":"2023-10-16T17:52:01.517Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3877123307,"revision":17453,"compact-revision":17214}
{"level":"info","ts":"2023-10-16T17:57:01.468Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":17693}
{"level":"info","ts":"2023-10-16T17:57:01.471Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":17693,"took":"1.907667ms","hash":3448278716}
{"level":"info","ts":"2023-10-16T17:57:01.471Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3448278716,"revision":17693,"compact-revision":17453}
{"level":"info","ts":"2023-10-16T18:02:01.475Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":17933}
{"level":"info","ts":"2023-10-16T18:02:01.477Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":17933,"took":"1.106541ms","hash":515435846}
{"level":"info","ts":"2023-10-16T18:02:01.477Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":515435846,"revision":17933,"compact-revision":17693}
{"level":"info","ts":"2023-10-16T18:07:01.482Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":18171}
{"level":"info","ts":"2023-10-16T18:07:01.484Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":18171,"took":"1.072417ms","hash":3822883682}
{"level":"info","ts":"2023-10-16T18:07:01.484Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3822883682,"revision":18171,"compact-revision":17933}
{"level":"info","ts":"2023-10-16T18:12:01.511Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":18412}
{"level":"info","ts":"2023-10-16T18:12:01.513Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":18412,"took":"1.665583ms","hash":1640210152}
{"level":"info","ts":"2023-10-16T18:12:01.513Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1640210152,"revision":18412,"compact-revision":18171}
{"level":"info","ts":"2023-10-16T19:35:59.729Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":18651}
{"level":"info","ts":"2023-10-16T19:35:59.733Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":18651,"took":"2.147584ms","hash":286211892}
{"level":"info","ts":"2023-10-16T19:35:59.733Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":286211892,"revision":18651,"compact-revision":18412}
{"level":"info","ts":"2023-10-16T19:40:59.727Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":18889}
{"level":"info","ts":"2023-10-16T19:40:59.733Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":18889,"took":"4.192125ms","hash":3623632955}
{"level":"info","ts":"2023-10-16T19:40:59.733Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3623632955,"revision":18889,"compact-revision":18651}
{"level":"info","ts":"2023-10-16T19:45:59.724Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":19128}
{"level":"info","ts":"2023-10-16T19:45:59.727Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":19128,"took":"2.135084ms","hash":1114725777}
{"level":"info","ts":"2023-10-16T19:45:59.727Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1114725777,"revision":19128,"compact-revision":18889}
{"level":"info","ts":"2023-10-16T19:50:59.721Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":19369}
{"level":"info","ts":"2023-10-16T19:50:59.725Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":19369,"took":"2.226875ms","hash":985969179}
{"level":"info","ts":"2023-10-16T19:50:59.725Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":985969179,"revision":19369,"compact-revision":19128}
{"level":"info","ts":"2023-10-16T19:55:59.736Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":19609}
{"level":"info","ts":"2023-10-16T19:55:59.740Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":19609,"took":"1.769292ms","hash":3150034031}
{"level":"info","ts":"2023-10-16T19:55:59.740Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3150034031,"revision":19609,"compact-revision":19369}
{"level":"info","ts":"2023-10-16T20:00:59.730Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":19848}
{"level":"info","ts":"2023-10-16T20:00:59.733Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":19848,"took":"1.748ms","hash":3154284904}
{"level":"info","ts":"2023-10-16T20:00:59.733Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3154284904,"revision":19848,"compact-revision":19609}
{"level":"info","ts":"2023-10-16T20:02:10.729Z","caller":"traceutil/trace.go:171","msg":"trace[1812469905] transaction","detail":"{read_only:false; response_revision:20145; number_of_response:1; }","duration":"151.667542ms","start":"2023-10-16T20:02:10.577Z","end":"2023-10-16T20:02:10.729Z","steps":["trace[1812469905] 'process raft request'  (duration: 62.901834ms)","trace[1812469905] 'store kv pair into bolt db' {req_type:put; key:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; req_size:582; } (duration: 88.492458ms)"],"step_count":2}
{"level":"info","ts":"2023-10-16T20:05:59.729Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":20087}
{"level":"info","ts":"2023-10-16T20:05:59.732Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":20087,"took":"1.774292ms","hash":2450580237}
{"level":"info","ts":"2023-10-16T20:05:59.732Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2450580237,"revision":20087,"compact-revision":19848}
{"level":"info","ts":"2023-10-16T20:10:59.729Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":20327}
{"level":"info","ts":"2023-10-16T20:10:59.731Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":20327,"took":"1.379542ms","hash":743608455}
{"level":"info","ts":"2023-10-16T20:10:59.731Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":743608455,"revision":20327,"compact-revision":20087}
{"level":"info","ts":"2023-10-16T20:15:59.751Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":20567}
{"level":"info","ts":"2023-10-16T20:15:59.754Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":20567,"took":"1.503167ms","hash":3063785438}
{"level":"info","ts":"2023-10-16T20:15:59.754Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3063785438,"revision":20567,"compact-revision":20327}
{"level":"info","ts":"2023-10-16T20:20:59.756Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":20806}
{"level":"info","ts":"2023-10-16T20:20:59.759Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":20806,"took":"1.845167ms","hash":466768502}
{"level":"info","ts":"2023-10-16T20:20:59.759Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":466768502,"revision":20806,"compact-revision":20567}
{"level":"info","ts":"2023-10-16T20:48:35.509Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":21047}
{"level":"info","ts":"2023-10-16T20:48:35.511Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":21047,"took":"1.19625ms","hash":519307818}
{"level":"info","ts":"2023-10-16T20:48:35.511Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":519307818,"revision":21047,"compact-revision":20806}
{"level":"info","ts":"2023-10-16T20:53:35.506Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":21285}
{"level":"info","ts":"2023-10-16T20:53:35.510Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":21285,"took":"2.148209ms","hash":3857540802}
{"level":"info","ts":"2023-10-16T20:53:35.510Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3857540802,"revision":21285,"compact-revision":21047}
{"level":"info","ts":"2023-10-16T20:58:35.506Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":21525}
{"level":"info","ts":"2023-10-16T20:58:35.509Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":21525,"took":"2.137917ms","hash":537909251}
{"level":"info","ts":"2023-10-16T20:58:35.509Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":537909251,"revision":21525,"compact-revision":21285}
{"level":"info","ts":"2023-10-16T21:03:35.494Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":21765}
{"level":"info","ts":"2023-10-16T21:03:35.495Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":21765,"took":"742.917µs","hash":493241324}
{"level":"info","ts":"2023-10-16T21:03:35.495Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":493241324,"revision":21765,"compact-revision":21525}

* 
* ==> kernel <==
*  18:10:02 up 23:21,  0 users,  load average: 0.24, 0.47, 0.57
Linux minikube 5.15.49-linuxkit #1 SMP PREEMPT Tue Sep 13 07:51:32 UTC 2022 aarch64 aarch64 aarch64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.2 LTS"

* 
* ==> kube-apiserver [66cf9747210a] <==
* I1015 09:13:40.298902       1 shared_informer.go:318] Caches are synced for node_authorizer
I1015 09:13:40.376633       1 shared_informer.go:318] Caches are synced for crd-autoregister
I1015 09:13:40.457899       1 aggregator.go:152] initial CRD sync complete...
I1015 09:13:40.458213       1 autoregister_controller.go:141] Starting autoregister controller
I1015 09:13:40.458465       1 cache.go:32] Waiting for caches to sync for autoregister controller
I1015 09:13:40.458527       1 cache.go:39] Caches are synced for autoregister controller
I1015 09:13:40.496381       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I1015 09:13:40.498873       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
E1015 09:13:40.506052       1 controller.go:146] "Failed to ensure lease exists, will retry" err="namespaces \"kube-system\" not found" interval="200ms"
I1015 09:13:40.710235       1 controller.go:624] quota admission added evaluator for: leases.coordination.k8s.io
I1015 09:13:41.128302       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I1015 09:13:41.134120       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I1015 09:13:41.134182       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I1015 09:13:41.414744       1 controller.go:624] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I1015 09:13:41.443998       1 controller.go:624] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I1015 09:13:41.482988       1 alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W1015 09:13:41.486508       1 lease.go:251] Resetting endpoints for master service "kubernetes" to [192.168.49.2]
I1015 09:13:41.487181       1 controller.go:624] quota admission added evaluator for: endpoints
I1015 09:13:41.489434       1 controller.go:624] quota admission added evaluator for: endpointslices.discovery.k8s.io
I1015 09:13:42.218927       1 controller.go:624] quota admission added evaluator for: serviceaccounts
I1015 09:13:43.250552       1 controller.go:624] quota admission added evaluator for: deployments.apps
I1015 09:13:43.258557       1 alloc.go:330] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I1015 09:13:43.265991       1 controller.go:624] quota admission added evaluator for: daemonsets.apps
I1015 09:13:55.223729       1 controller.go:624] quota admission added evaluator for: controllerrevisions.apps
I1015 09:13:55.324437       1 controller.go:624] quota admission added evaluator for: replicasets.apps
E1015 10:49:35.363316       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 10:49:35.690138       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 12:27:18.756596       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 12:27:19.057133       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 15:36:20.678521       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 15:36:20.948505       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 18:00:35.476629       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 18:00:35.653153       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 21:04:43.781952       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 21:04:43.781950       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
I1015 22:24:44.589109       1 alloc.go:330] "allocated clusterIPs" service="default/service-registry-svc" clusterIPs=map[IPv4:10.110.191.49]
E1015 22:58:07.758905       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1015 22:58:07.900181       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 01:11:04.422782       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 01:11:04.422783       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 03:25:04.740025       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 03:25:04.740057       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 04:48:13.011084       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 04:48:13.011130       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 06:45:34.647528       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 06:45:34.647528       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 09:36:44.855476       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 09:36:44.855679       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 11:27:32.674545       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 11:27:32.674548       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 13:10:03.527005       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 13:10:03.527003       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 16:17:27.959752       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 16:17:27.959751       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
I1016 17:32:00.928505       1 trace.go:219] Trace[418563140]: "DeltaFIFO Pop Process" ID:v1.networking.k8s.io,Depth:19,Reason:slow event handlers blocking the queue (16-Oct-2023 17:32:00.793) (total time: 130ms):
Trace[418563140]: [130.855292ms] [130.855292ms] END
E1016 19:35:55.089717       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 19:35:55.090630       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 20:45:31.888320       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1016 20:45:31.888776       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"

* 
* ==> kube-apiserver [b783d326de45] <==
* I1022 08:23:20.053949       1 controller.go:80] Starting OpenAPI V3 AggregationController
I1022 08:23:20.053554       1 system_namespaces_controller.go:67] Starting system namespaces controller
I1022 08:23:20.054200       1 controller.go:121] Starting legacy_token_tracking_controller
I1022 08:23:20.054210       1 shared_informer.go:311] Waiting for caches to sync for configmaps
I1022 08:23:20.054327       1 gc_controller.go:78] Starting apiserver lease garbage collector
I1022 08:23:20.054801       1 handler_discovery.go:392] Starting ResourceDiscoveryManager
I1022 08:23:20.054853       1 apf_controller.go:361] Starting API Priority and Fairness config controller
I1022 08:23:20.055030       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I1022 08:23:20.069437       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I1022 08:23:20.069481       1 shared_informer.go:311] Waiting for caches to sync for crd-autoregister
E1022 08:23:20.090302       1 controller.go:155] Error removing old endpoints from kubernetes service: no master IPs were listed in storage, refusing to erase all endpoints for the kubernetes service
I1022 08:23:20.102318       1 controller.go:624] quota admission added evaluator for: leases.coordination.k8s.io
I1022 08:23:20.163298       1 apf_controller.go:366] Running API Priority and Fairness config worker
I1022 08:23:20.163320       1 apf_controller.go:369] Running API Priority and Fairness periodic rebalancing process
I1022 08:23:20.167968       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I1022 08:23:20.173312       1 shared_informer.go:318] Caches are synced for node_authorizer
I1022 08:23:20.173701       1 shared_informer.go:318] Caches are synced for configmaps
I1022 08:23:20.174145       1 shared_informer.go:318] Caches are synced for crd-autoregister
I1022 08:23:20.174551       1 aggregator.go:152] initial CRD sync complete...
I1022 08:23:20.174641       1 autoregister_controller.go:141] Starting autoregister controller
I1022 08:23:20.174663       1 cache.go:32] Waiting for caches to sync for autoregister controller
I1022 08:23:20.174679       1 cache.go:39] Caches are synced for autoregister controller
I1022 08:23:20.179214       1 shared_informer.go:318] Caches are synced for cluster_authentication_trust_controller
I1022 08:23:20.182203       1 cache.go:39] Caches are synced for AvailableConditionController controller
I1022 08:23:20.775131       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I1022 08:23:21.069187       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I1022 08:23:21.932093       1 controller.go:624] quota admission added evaluator for: serviceaccounts
I1022 08:23:21.972179       1 controller.go:624] quota admission added evaluator for: deployments.apps
I1022 08:23:22.004971       1 controller.go:624] quota admission added evaluator for: daemonsets.apps
I1022 08:23:22.064099       1 controller.go:624] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I1022 08:23:22.070658       1 controller.go:624] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I1022 08:23:23.764522       1 controller.go:624] quota admission added evaluator for: endpoints
I1022 08:23:33.299442       1 controller.go:624] quota admission added evaluator for: endpointslices.discovery.k8s.io
E1022 09:36:16.808919       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 09:36:17.097499       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 11:24:32.214640       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 11:24:32.443504       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 12:39:46.629989       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 12:39:46.879796       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 16:30:28.283783       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 16:30:28.691873       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
I1022 17:10:56.418490       1 controller.go:624] quota admission added evaluator for: namespaces
E1022 17:10:56.448169       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
I1022 17:10:56.455293       1 controller.go:624] quota admission added evaluator for: replicasets.apps
E1022 17:10:56.459298       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
I1022 17:10:56.553034       1 alloc.go:330] "allocated clusterIPs" service="kubernetes-dashboard/kubernetes-dashboard" clusterIPs=map[IPv4:10.98.205.5]
E1022 17:10:56.554941       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 17:10:56.555903       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
I1022 17:10:56.567524       1 alloc.go:330] "allocated clusterIPs" service="kubernetes-dashboard/dashboard-metrics-scraper" clusterIPs=map[IPv4:10.101.81.184]
I1022 17:17:55.068988       1 alloc.go:330] "allocated clusterIPs" service="default/cloud-gateway-svc" clusterIPs=map[IPv4:10.104.185.21]
I1022 17:17:55.123344       1 alloc.go:330] "allocated clusterIPs" service="default/config-service-svc" clusterIPs=map[IPv4:10.105.125.30]
I1022 17:17:55.146787       1 controller.go:624] quota admission added evaluator for: statefulsets.apps
I1022 17:17:55.153717       1 controller.go:624] quota admission added evaluator for: controllerrevisions.apps
I1022 17:17:55.169265       1 alloc.go:330] "allocated clusterIPs" service="default/order-service-svc" clusterIPs=map[IPv4:10.104.19.179]
I1022 17:17:55.223008       1 alloc.go:330] "allocated clusterIPs" service="default/payment-service-svc" clusterIPs=map[IPv4:10.110.149.57]
I1022 17:17:55.242999       1 alloc.go:330] "allocated clusterIPs" service="default/product-service-svc" clusterIPs=map[IPv4:10.111.180.237]
I1022 17:17:55.258759       1 alloc.go:330] "allocated clusterIPs" service="default/redis" clusterIPs=map[IPv4:10.104.82.206]
I1022 17:17:55.317603       1 alloc.go:330] "allocated clusterIPs" service="default/eureka-lb" clusterIPs=map[IPv4:10.104.158.154]
E1022 17:46:44.393165       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"
E1022 17:46:44.782570       1 authentication.go:70] "Unable to authenticate the request" err="[invalid bearer token, service account token has expired]"

* 
* ==> kube-controller-manager [283915b50eb3] <==
* I1022 17:10:56.490005       1 event.go:307] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard-5c5cfc8747" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kubernetes-dashboard-5c5cfc8747-6b2mh"
I1022 17:10:56.491373       1 event.go:307] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-5dd9cbfd69" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: dashboard-metrics-scraper-5dd9cbfd69-2fl69"
W1022 17:10:56.555284       1 endpointslice_controller.go:297] Error syncing endpoint slices for service "kubernetes-dashboard/kubernetes-dashboard", retrying. Error: failed to create EndpointSlice for Service kubernetes-dashboard/kubernetes-dashboard: Unauthorized
I1022 17:10:56.555484       1 event.go:298] Event(v1.ObjectReference{Kind:"Service", Namespace:"kubernetes-dashboard", Name:"kubernetes-dashboard", UID:"c7adcce8-420a-4d94-a583-4fe6f6bb382f", APIVersion:"v1", ResourceVersion:"22979", FieldPath:""}): type: 'Warning' reason: 'FailedToUpdateEndpointSlices' Error updating Endpoint Slices for Service kubernetes-dashboard/kubernetes-dashboard: failed to create EndpointSlice for Service kubernetes-dashboard/kubernetes-dashboard: Unauthorized
I1022 17:10:56.556205       1 event.go:307] "Event occurred" object="kubernetes-dashboard" fieldPath="" kind="Endpoints" apiVersion="v1" type="Warning" reason="FailedToCreateEndpoint" message="Failed to create endpoint for service kubernetes-dashboard/kubernetes-dashboard: Unauthorized"
I1022 17:17:55.063120       1 event.go:307] "Event occurred" object="default/cloud-gateway-app" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set cloud-gateway-app-684b844c64 to 1"
I1022 17:17:55.069783       1 event.go:307] "Event occurred" object="default/cloud-gateway-app-684b844c64" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: cloud-gateway-app-684b844c64-7pw68"
I1022 17:17:55.114321       1 event.go:307] "Event occurred" object="default/config-server-app" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set config-server-app-57bf8b9f8f to 1"
I1022 17:17:55.118257       1 event.go:307] "Event occurred" object="default/config-server-app-57bf8b9f8f" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: config-server-app-57bf8b9f8f-nqgm9"
E1022 17:17:55.142817       1 pv_controller.go:1571] "Error finding provisioning plugin for claim" err="storageclass.storage.k8s.io \"manual\" not found" PVC="default/mysql-pv"
I1022 17:17:55.142935       1 event.go:307] "Event occurred" object="default/mysql-pv" fieldPath="" kind="PersistentVolumeClaim" apiVersion="v1" type="Warning" reason="ProvisioningFailed" message="storageclass.storage.k8s.io \"manual\" not found"
I1022 17:17:55.159087       1 event.go:307] "Event occurred" object="default/mysql" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod mysql-0 in StatefulSet mysql successful"
I1022 17:17:55.162086       1 event.go:307] "Event occurred" object="default/order-service-app" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set order-service-app-6c98f7fd45 to 1"
I1022 17:17:55.168480       1 event.go:307] "Event occurred" object="default/order-service-app-6c98f7fd45" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: order-service-app-6c98f7fd45-sks5h"
I1022 17:17:55.211360       1 event.go:307] "Event occurred" object="default/payment-service-app" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set payment-service-app-c544599f6 to 1"
I1022 17:17:55.215098       1 event.go:307] "Event occurred" object="default/payment-service-app-c544599f6" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: payment-service-app-c544599f6-wl8dq"
I1022 17:17:55.233244       1 event.go:307] "Event occurred" object="default/product-service-app" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set product-service-app-77b9cbc65d to 1"
I1022 17:17:55.236554       1 event.go:307] "Event occurred" object="default/product-service-app-77b9cbc65d" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: product-service-app-77b9cbc65d-77zff"
I1022 17:17:55.251888       1 event.go:307] "Event occurred" object="default/redis-app" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set redis-app-75474c45c to 1"
I1022 17:17:55.254375       1 event.go:307] "Event occurred" object="default/redis-app-75474c45c" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: redis-app-75474c45c-fjm94"
I1022 17:17:55.271815       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:55.274113       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
E1022 17:17:55.309339       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:55.309706       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:55.311480       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:55.311522       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:55.321221       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:55.321249       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:55.363138       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:55.363233       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:55.446908       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:55.447070       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:55.609624       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:55.609808       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:55.931790       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:55.931928       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:56.579768       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:56.580434       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:17:57.869490       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:17:57.869616       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:18:00.436019       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:18:00.436131       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:18:05.563269       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:18:05.563644       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:18:15.808188       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:18:15.808369       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:18:36.297427       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:18:36.297560       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:19:17.272264       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:19:17.272706       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:20:39.203464       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:20:39.203691       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:23:23.059991       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:23:23.060193       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:31:43.121972       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:31:43.122414       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
E1022 17:46:44.394063       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1022 17:46:44.783781       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1022 17:55:47.109479       1 stateful_set.go:430] error syncing StatefulSet default/eureka, requeuing: Pod "eureka-0" is invalid: spec.subdomain: Invalid value: "“eureka”": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
I1022 17:55:47.109669       1 event.go:307] "Event occurred" object="default/eureka" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="create Pod eureka-0 in StatefulSet eureka failed error: Pod \"eureka-0\" is invalid: spec.subdomain: Invalid value: \"“eureka”\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"

* 
* ==> kube-controller-manager [36dcbf7d8cf8] <==
* I1015 09:13:55.087957       1 shared_informer.go:318] Caches are synced for cidrallocator
I1015 09:13:55.091345       1 shared_informer.go:318] Caches are synced for taint
I1015 09:13:55.091782       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I1015 09:13:55.091833       1 taint_manager.go:211] "Sending events to api server"
I1015 09:13:55.092057       1 node_lifecycle_controller.go:1223] "Initializing eviction metric for zone" zone=""
I1015 09:13:55.092578       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I1015 09:13:55.092603       1 node_lifecycle_controller.go:875] "Missing timestamp for Node. Assuming now as a timestamp" node="minikube"
I1015 09:13:55.092785       1 node_lifecycle_controller.go:1069] "Controller detected that zone is now in new state" zone="" newState=Normal
I1015 09:13:55.095637       1 shared_informer.go:318] Caches are synced for service account
I1015 09:13:55.096938       1 range_allocator.go:380] "Set node PodCIDR" node="minikube" podCIDRs=[10.244.0.0/24]
I1015 09:13:55.183166       1 shared_informer.go:318] Caches are synced for resource quota
I1015 09:13:55.185746       1 shared_informer.go:318] Caches are synced for resource quota
I1015 09:13:55.216877       1 shared_informer.go:318] Caches are synced for endpoint_slice
I1015 09:13:55.222025       1 shared_informer.go:318] Caches are synced for endpoint_slice_mirroring
I1015 09:13:55.232052       1 event.go:307] "Event occurred" object="kube-system/kube-proxy" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-cl7h2"
I1015 09:13:55.279157       1 shared_informer.go:318] Caches are synced for endpoint
I1015 09:13:55.329100       1 event.go:307] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-5d78c9869d to 1"
I1015 09:13:55.617042       1 shared_informer.go:318] Caches are synced for garbage collector
I1015 09:13:55.638799       1 shared_informer.go:318] Caches are synced for garbage collector
I1015 09:13:55.638912       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"
I1015 09:13:56.079354       1 event.go:307] "Event occurred" object="kube-system/coredns-5d78c9869d" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-5d78c9869d-rfsxg"
E1015 10:49:35.365161       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1015 10:49:35.690851       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1015 12:27:18.757459       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1015 12:27:19.058499       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1015 15:36:20.680261       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1015 15:36:20.949620       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1015 18:00:35.478554       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1015 18:00:35.654559       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
I1015 18:41:40.692491       1 cleaner.go:172] Cleaning CSR "csr-7ts5g" as it is more than 1h0m0s old and approved.
I1015 19:45:21.268906       1 event.go:307] "Event occurred" object="default/nginx" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set nginx-77b4fdf86c to 1"
I1015 19:45:21.280340       1 event.go:307] "Event occurred" object="default/nginx-77b4fdf86c" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: nginx-77b4fdf86c-xgdlk"
W1015 21:04:43.784319       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1015 21:04:43.784622       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
I1015 22:23:33.761432       1 event.go:307] "Event occurred" object="default/service-registry" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set service-registry-69c6c987f8 to 1"
I1015 22:23:33.776506       1 event.go:307] "Event occurred" object="default/service-registry-69c6c987f8" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: service-registry-69c6c987f8-jpdzs"
E1015 22:58:07.761288       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1015 22:58:07.901692       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
I1015 22:59:19.404517       1 event.go:307] "Event occurred" object="microservices/service-registry" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set service-registry-69c6c987f8 to 1"
I1015 22:59:19.411225       1 event.go:307] "Event occurred" object="microservices/service-registry-69c6c987f8" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: service-registry-69c6c987f8-cs8ff"
W1016 01:11:04.424231       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1016 01:11:04.424303       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E1016 03:25:04.741948       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1016 03:25:04.741947       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W1016 04:48:13.012336       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1016 04:48:13.012412       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1016 06:45:34.649670       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1016 06:45:34.649806       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E1016 09:36:44.857288       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1016 09:36:44.857248       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W1016 11:27:32.677267       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1016 11:27:32.677390       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E1016 13:10:03.528456       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1016 13:10:03.528444       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
W1016 16:17:27.960829       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1016 16:17:27.960847       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1016 19:35:55.091015       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials
E1016 19:35:55.091837       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
E1016 20:45:31.890048       1 resource_quota_controller.go:441] failed to discover resources: the server has asked for the client to provide credentials
W1016 20:45:31.890038       1 garbagecollector.go:818] failed to discover preferred resources: the server has asked for the client to provide credentials

* 
* ==> kube-proxy [6ddc40bc591f] <==
* I1022 08:23:22.281743       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I1022 08:23:22.283227       1 server_others.go:110] "Detected node IP" address="192.168.49.2"
I1022 08:23:22.283266       1 server_others.go:554] "Using iptables proxy"
I1022 08:23:22.413793       1 server_others.go:192] "Using iptables Proxier"
I1022 08:23:22.413826       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I1022 08:23:22.413833       1 server_others.go:200] "Creating dualStackProxier for iptables"
I1022 08:23:22.413844       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I1022 08:23:22.414511       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I1022 08:23:22.415629       1 server.go:658] "Version info" version="v1.27.4"
I1022 08:23:22.415772       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1022 08:23:22.417827       1 config.go:188] "Starting service config controller"
I1022 08:23:22.418382       1 shared_informer.go:311] Waiting for caches to sync for service config
I1022 08:23:22.418521       1 config.go:97] "Starting endpoint slice config controller"
I1022 08:23:22.418530       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I1022 08:23:22.418619       1 config.go:315] "Starting node config controller"
I1022 08:23:22.418642       1 shared_informer.go:311] Waiting for caches to sync for node config
I1022 08:23:22.520937       1 shared_informer.go:318] Caches are synced for service config
I1022 08:23:22.520951       1 shared_informer.go:318] Caches are synced for endpoint slice config
I1022 08:23:22.521499       1 shared_informer.go:318] Caches are synced for node config

* 
* ==> kube-proxy [bae908757963] <==
* I1015 09:13:56.826361       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I1015 09:13:56.826523       1 server_others.go:110] "Detected node IP" address="192.168.49.2"
I1015 09:13:56.826581       1 server_others.go:554] "Using iptables proxy"
I1015 09:13:56.985720       1 server_others.go:192] "Using iptables Proxier"
I1015 09:13:56.985755       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I1015 09:13:56.985761       1 server_others.go:200] "Creating dualStackProxier for iptables"
I1015 09:13:56.985773       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I1015 09:13:56.985889       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I1015 09:13:56.986643       1 server.go:658] "Version info" version="v1.27.4"
I1015 09:13:56.986662       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1015 09:13:56.987523       1 config.go:97] "Starting endpoint slice config controller"
I1015 09:13:56.987607       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I1015 09:13:56.987670       1 config.go:188] "Starting service config controller"
I1015 09:13:56.987674       1 shared_informer.go:311] Waiting for caches to sync for service config
I1015 09:13:56.988202       1 config.go:315] "Starting node config controller"
I1015 09:13:56.988212       1 shared_informer.go:311] Waiting for caches to sync for node config
I1015 09:13:57.088234       1 shared_informer.go:318] Caches are synced for service config
I1015 09:13:57.088275       1 shared_informer.go:318] Caches are synced for node config
I1015 09:13:57.088312       1 shared_informer.go:318] Caches are synced for endpoint slice config

* 
* ==> kube-scheduler [d029e09f6113] <==
* I1022 08:23:18.003064       1 serving.go:348] Generated self-signed cert in-memory
W1022 08:23:20.089798       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W1022 08:23:20.090141       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W1022 08:23:20.090343       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W1022 08:23:20.090579       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I1022 08:23:20.189493       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.27.4"
I1022 08:23:20.189576       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1022 08:23:20.193278       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I1022 08:23:20.193681       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I1022 08:23:20.198298       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I1022 08:23:20.198692       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I1022 08:23:20.294280       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kube-scheduler [da6aa7eea63e] <==
* I1015 09:13:37.962756       1 serving.go:348] Generated self-signed cert in-memory
W1015 09:13:40.189672       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W1015 09:13:40.196190       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W1015 09:13:40.196457       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W1015 09:13:40.196582       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I1015 09:13:40.283356       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.27.4"
I1015 09:13:40.284415       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1015 09:13:40.291127       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I1015 09:13:40.291372       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I1015 09:13:40.299924       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I1015 09:13:40.300193       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W1015 09:13:40.301066       1 reflector.go:533] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E1015 09:13:40.301183       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W1015 09:13:40.378717       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E1015 09:13:40.379407       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W1015 09:13:40.379672       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E1015 09:13:40.379724       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W1015 09:13:40.410418       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E1015 09:13:40.410463       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W1015 09:13:40.410929       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E1015 09:13:40.410966       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W1015 09:13:40.461601       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E1015 09:13:40.461655       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W1015 09:13:40.461783       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E1015 09:13:40.461811       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W1015 09:13:40.461875       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E1015 09:13:40.461884       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W1015 09:13:40.461962       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E1015 09:13:40.461982       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W1015 09:13:40.462240       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E1015 09:13:40.462284       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W1015 09:13:40.462390       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E1015 09:13:40.462412       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W1015 09:13:40.462471       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E1015 09:13:40.466945       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W1015 09:13:40.462677       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E1015 09:13:40.467353       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W1015 09:13:40.462645       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E1015 09:13:40.467374       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W1015 09:13:40.466283       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E1015 09:13:40.467402       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W1015 09:13:41.228619       1 reflector.go:533] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E1015 09:13:41.228671       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W1015 09:13:41.310794       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E1015 09:13:41.310825       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W1015 09:13:41.323008       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E1015 09:13:41.323037       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
I1015 09:13:43.291995       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* Oct 22 18:07:32 minikube kubelet[1474]: E1022 18:07:32.544673    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:07:36 minikube kubelet[1474]: E1022 18:07:36.540755    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:07:36 minikube kubelet[1474]: E1022 18:07:36.540822    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:07:38 minikube kubelet[1474]: E1022 18:07:38.544892    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:07:40 minikube kubelet[1474]: E1022 18:07:40.549121    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:07:46 minikube kubelet[1474]: E1022 18:07:46.544344    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:07:50 minikube kubelet[1474]: E1022 18:07:50.543348    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:07:51 minikube kubelet[1474]: E1022 18:07:51.540116    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:07:53 minikube kubelet[1474]: E1022 18:07:53.545454    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:07:54 minikube kubelet[1474]: E1022 18:07:54.544839    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:08:01 minikube kubelet[1474]: E1022 18:08:01.543067    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:08:02 minikube kubelet[1474]: E1022 18:08:02.543507    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:08:02 minikube kubelet[1474]: E1022 18:08:02.544101    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:08:07 minikube kubelet[1474]: E1022 18:08:07.544076    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:08:08 minikube kubelet[1474]: E1022 18:08:08.543644    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:08:14 minikube kubelet[1474]: E1022 18:08:14.542375    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:08:14 minikube kubelet[1474]: E1022 18:08:14.542592    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:08:15 minikube kubelet[1474]: E1022 18:08:15.546355    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:08:21 minikube kubelet[1474]: E1022 18:08:21.541796    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:08:21 minikube kubelet[1474]: E1022 18:08:21.543272    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:08:25 minikube kubelet[1474]: E1022 18:08:25.548738    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:08:29 minikube kubelet[1474]: E1022 18:08:29.542391    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:08:30 minikube kubelet[1474]: E1022 18:08:30.541045    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:08:32 minikube kubelet[1474]: E1022 18:08:32.540407    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:08:34 minikube kubelet[1474]: E1022 18:08:34.539305    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:08:38 minikube kubelet[1474]: E1022 18:08:38.544058    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:08:40 minikube kubelet[1474]: E1022 18:08:40.545016    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:08:41 minikube kubelet[1474]: E1022 18:08:41.546071    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:08:46 minikube kubelet[1474]: E1022 18:08:46.541650    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:08:48 minikube kubelet[1474]: E1022 18:08:48.543334    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:08:51 minikube kubelet[1474]: E1022 18:08:51.539443    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:08:52 minikube kubelet[1474]: E1022 18:08:52.541755    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:08:55 minikube kubelet[1474]: E1022 18:08:55.541403    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:09:01 minikube kubelet[1474]: E1022 18:09:01.542137    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:09:03 minikube kubelet[1474]: E1022 18:09:03.542132    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:09:05 minikube kubelet[1474]: E1022 18:09:05.557855    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:09:07 minikube kubelet[1474]: E1022 18:09:07.541525    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:09:09 minikube kubelet[1474]: E1022 18:09:09.539947    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:09:14 minikube kubelet[1474]: E1022 18:09:14.540513    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:09:16 minikube kubelet[1474]: E1022 18:09:16.537764    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:09:19 minikube kubelet[1474]: E1022 18:09:19.538486    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:09:20 minikube kubelet[1474]: E1022 18:09:20.541303    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:09:20 minikube kubelet[1474]: E1022 18:09:20.541733    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:09:25 minikube kubelet[1474]: W1022 18:09:25.543524    1474 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Oct 22 18:09:25 minikube kubelet[1474]: W1022 18:09:25.546461    1474 machine.go:65] Cannot read vendor id correctly, set empty.
Oct 22 18:09:29 minikube kubelet[1474]: E1022 18:09:29.541878    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:09:29 minikube kubelet[1474]: E1022 18:09:29.542012    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:09:33 minikube kubelet[1474]: E1022 18:09:33.543221    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:09:33 minikube kubelet[1474]: E1022 18:09:33.543414    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:09:34 minikube kubelet[1474]: E1022 18:09:34.541423    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:09:41 minikube kubelet[1474]: E1022 18:09:41.538457    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:09:43 minikube kubelet[1474]: E1022 18:09:43.538452    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:09:45 minikube kubelet[1474]: E1022 18:09:45.543925    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb
Oct 22 18:09:45 minikube kubelet[1474]: E1022 18:09:45.544750    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:09:46 minikube kubelet[1474]: E1022 18:09:46.536814    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:09:54 minikube kubelet[1474]: E1022 18:09:54.540930    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"payment-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/paymentservice\\\"\"" pod="default/payment-service-app-c544599f6-wl8dq" podUID=056b8178-04bb-42c3-82c0-e381d8cba2ec
Oct 22 18:09:57 minikube kubelet[1474]: E1022 18:09:57.539988    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"order-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/orderservice\\\"\"" pod="default/order-service-app-6c98f7fd45-sks5h" podUID=3da067d0-d39c-4f6e-9e5d-2d000821e086
Oct 22 18:09:58 minikube kubelet[1474]: E1022 18:09:58.538791    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"config-server-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/configserver\\\"\"" pod="default/config-server-app-57bf8b9f8f-nqgm9" podUID=1318dffb-269d-4db3-9911-8d9b07cc6fe4
Oct 22 18:09:58 minikube kubelet[1474]: E1022 18:09:58.538894    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"product-service-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/productservice\\\"\"" pod="default/product-service-app-77b9cbc65d-77zff" podUID=37289d7b-83d3-433c-b109-3a6646643b02
Oct 22 18:10:00 minikube kubelet[1474]: E1022 18:10:00.537618    1474 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cloud-gateway-app\" with ImagePullBackOff: \"Back-off pulling image \\\"sinianliu/cloudgateway\\\"\"" pod="default/cloud-gateway-app-684b844c64-7pw68" podUID=dfaea6b0-1274-40ee-afcd-504900561ffb

* 
* ==> kubernetes-dashboard [99e010e50d66] <==
* 2023/10/22 18:09:46 [2023-10-22T18:09:46Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/10/22 18:09:46 Getting list of namespaces
2023/10/22 18:09:46 [2023-10-22T18:09:46Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:46 [2023-10-22T18:09:46Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68 request from 127.0.0.1: 
2023/10/22 18:09:46 Getting details of cloud-gateway-app-684b844c64-7pw68 pod in default namespace
2023/10/22 18:09:46 [2023-10-22T18:09:46Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68/event?itemsPerPage=10&page=1&sortBy=d,lastSeen request from 127.0.0.1: 
2023/10/22 18:09:46 Getting events related to a pod in namespace
2023/10/22 18:09:46 [2023-10-22T18:09:46Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68/persistentvolumeclaim?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/10/22 18:09:46 [2023-10-22T18:09:46Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:46 No persistentvolumeclaims found related to cloud-gateway-app-684b844c64-7pw68 pod
2023/10/22 18:09:46 [2023-10-22T18:09:46Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:46 received 0 resources from sidecar instead of 1
2023/10/22 18:09:46 received 0 resources from sidecar instead of 1
2023/10/22 18:09:46 No persistentvolumeclaims found related to cloud-gateway-app-684b844c64-7pw68 pod
2023/10/22 18:09:46 [2023-10-22T18:09:46Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:51 [2023-10-22T18:09:51Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/10/22 18:09:51 Getting list of namespaces
2023/10/22 18:09:51 [2023-10-22T18:09:51Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:51 [2023-10-22T18:09:51Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68 request from 127.0.0.1: 
2023/10/22 18:09:51 Getting details of cloud-gateway-app-684b844c64-7pw68 pod in default namespace
2023/10/22 18:09:51 [2023-10-22T18:09:51Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68/event?itemsPerPage=10&page=1&sortBy=d,lastSeen request from 127.0.0.1: 
2023/10/22 18:09:51 Getting events related to a pod in namespace
2023/10/22 18:09:51 [2023-10-22T18:09:51Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68/persistentvolumeclaim?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/10/22 18:09:51 [2023-10-22T18:09:51Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:51 No persistentvolumeclaims found related to cloud-gateway-app-684b844c64-7pw68 pod
2023/10/22 18:09:51 [2023-10-22T18:09:51Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:51 received 0 resources from sidecar instead of 1
2023/10/22 18:09:51 received 0 resources from sidecar instead of 1
2023/10/22 18:09:51 No persistentvolumeclaims found related to cloud-gateway-app-684b844c64-7pw68 pod
2023/10/22 18:09:51 [2023-10-22T18:09:51Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:56 [2023-10-22T18:09:56Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/10/22 18:09:56 Getting list of namespaces
2023/10/22 18:09:56 [2023-10-22T18:09:56Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68 request from 127.0.0.1: 
2023/10/22 18:09:56 Getting details of cloud-gateway-app-684b844c64-7pw68 pod in default namespace
2023/10/22 18:09:56 [2023-10-22T18:09:56Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68/event?itemsPerPage=10&page=1&sortBy=d,lastSeen request from 127.0.0.1: 
2023/10/22 18:09:56 Getting events related to a pod in namespace
2023/10/22 18:09:56 [2023-10-22T18:09:56Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68/persistentvolumeclaim?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/10/22 18:09:56 [2023-10-22T18:09:56Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:56 [2023-10-22T18:09:56Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:56 No persistentvolumeclaims found related to cloud-gateway-app-684b844c64-7pw68 pod
2023/10/22 18:09:56 [2023-10-22T18:09:56Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:09:56 received 0 resources from sidecar instead of 1
2023/10/22 18:09:56 received 0 resources from sidecar instead of 1
2023/10/22 18:09:56 No persistentvolumeclaims found related to cloud-gateway-app-684b844c64-7pw68 pod
2023/10/22 18:09:56 [2023-10-22T18:09:56Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:10:01 [2023-10-22T18:10:01Z] Incoming HTTP/1.1 GET /api/v1/namespace request from 127.0.0.1: 
2023/10/22 18:10:01 Getting list of namespaces
2023/10/22 18:10:01 [2023-10-22T18:10:01Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:10:01 [2023-10-22T18:10:01Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68/event?itemsPerPage=10&page=1&sortBy=d,lastSeen request from 127.0.0.1: 
2023/10/22 18:10:01 Getting events related to a pod in namespace
2023/10/22 18:10:01 [2023-10-22T18:10:01Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68/persistentvolumeclaim?itemsPerPage=10&page=1&sortBy=d,creationTimestamp request from 127.0.0.1: 
2023/10/22 18:10:01 [2023-10-22T18:10:01Z] Incoming HTTP/1.1 GET /api/v1/pod/default/cloud-gateway-app-684b844c64-7pw68 request from 127.0.0.1: 
2023/10/22 18:10:01 Getting details of cloud-gateway-app-684b844c64-7pw68 pod in default namespace
2023/10/22 18:10:01 No persistentvolumeclaims found related to cloud-gateway-app-684b844c64-7pw68 pod
2023/10/22 18:10:01 [2023-10-22T18:10:01Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:10:01 [2023-10-22T18:10:01Z] Outcoming response to 127.0.0.1 with 200 status code
2023/10/22 18:10:01 received 0 resources from sidecar instead of 1
2023/10/22 18:10:01 received 0 resources from sidecar instead of 1
2023/10/22 18:10:01 No persistentvolumeclaims found related to cloud-gateway-app-684b844c64-7pw68 pod
2023/10/22 18:10:01 [2023-10-22T18:10:01Z] Outcoming response to 127.0.0.1 with 200 status code

* 
* ==> storage-provisioner [1737bfc2a66b] <==
* I1022 08:23:21.924225       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F1022 08:23:26.968083       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: connect: connection refused

* 
* ==> storage-provisioner [34c587b33a9f] <==
* I1022 08:23:40.781742       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I1022 08:23:40.793781       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I1022 08:23:40.794274       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I1022 08:23:58.216179       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I1022 08:23:58.216725       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_20ff47e9-eb46-42de-94e8-b75dc3020789!
I1022 08:23:58.216782       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"d7bd469c-1107-4b9c-b53f-6f5c9e63d07c", APIVersion:"v1", ResourceVersion:"22362", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_20ff47e9-eb46-42de-94e8-b75dc3020789 became leader
I1022 08:23:58.320796       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_20ff47e9-eb46-42de-94e8-b75dc3020789!

